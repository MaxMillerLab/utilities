{
  "collection_time": "2025-08-01T12:57:19.344670+00:00",
  "repositories": {
    "MaxMillerLab/finance_and_dev": [
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjE3MTMxMzQ5",
            "login": "suproteemsarkar",
            "name": "Suproteem Sarkar"
          },
          {
            "id": "U_kgDOCAOw7w",
            "login": "ChernXiangyu",
            "name": "Xiangyu Chen"
          }
        ],
        "body": "We aim to transform the OCR output of financial reports into embedding vectors to support potential tasks such as summary statistics and regression, traditional downstream tasks like clustering, semantic search, and topic modeling. There are a few key components that need to be discussed and finalized:\n\n### 1. **Choice of Embedding Model**\n\nWe need to select an appropriate embedding model that balances performance, efficiency, and compatibility with our use case. Here are a few candidates under consideration:\n\n- [[RepresentLM-v1](https://huggingface.co/RepresentLM/RepresentLM-v1)](https://huggingface.co/RepresentLM/RepresentLM-v1): A clean, task-agnostic model trained without look-ahead bias, suitable for general-purpose embedding.\n- [[NV-Embed-v2 (NVIDIA)](https://huggingface.co/nvidia/NV-Embed-v2)](https://huggingface.co/nvidia/NV-Embed-v2): A large, high-performance embedding model with state-of-the-art capabilities.\n\nOther models:\n- [[ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base)](https://huggingface.co/answerdotai/ModernBERT-base): A modern BERT-style model that supports longer input sequences (up to 8192 tokens), improving contextual representation for long-form text.\n- [[Jina CLIP v2](https://huggingface.co/jinaai/jina-clip-v2)](https://huggingface.co/jinaai/jina-clip-v2): A multimodal model that can embed both text and images\u2014potentially useful for capturing embedded charts or tables in reports.\n\nWe can refer tp the [[MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard)](https://huggingface.co/spaces/mteb/leaderboard) to evaluate models across a wide range of tasks.\n\n\n### 2. **Handling Long Texts and Chunking Strategy**\n\nDue to input length limitations of most embedding models (typically 256 to 8192 tokens), we need an effective chunking strategy for long OCR documents:\n\n- BERT-based models: typically limited to 512 tokens.\n- Longer-context models can help reduce information loss due to truncation.\n- A **sliding window** approach (e.g., 50% overlap) can help to preserve context across adjacent segments.\n\n\n### 3. **Aggregation Strategy for Report-Level Embeddings**\n\nTo obtain a unified representation of an entire report composed of multiple chunks, we should consider:\n\n- **Simple average** of chunk-level embeddings.\n- **Weighted aggregation**, e.g., by chunk length, confidence score, or position.\n- **No aggregation**, keeping segment-level vectors for more fine-grained analysis.\n\n\n### 4. **Storage Format for Embedding Vectors**\n\nOnce embeddings are generated, we need to choose a storage solution that best fits our scale and usage patterns:\n\n- **Chroma**: Convenient and supports persistent storage to disk. Easy to use but relatively slow for large-scale retrieval.\n- **Faiss**: Fast and powerful for similarity search, but works in-memory. Ideal for server-side usage where memory is sufficient.\n- **Parquet (batch saving via pandas/dask, recommended for saving in the first place) + Numpy**: Flexible (could change distance measurement easily), easy to use, and accurate. Supports scalable batch processing, and avoids the approximation errors that come with vector databases using ANN (Approximate Nearest Neighbor) techniques.",
        "comments": [
          {
            "id": "IC_kwDOLsb5Oc6phpW0",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Aside from traditional embedding model, ColBERT (Contextualized Late Interaction over BERT) could represents text as a matrix of token-level embeddings rather than a single vector: https://huggingface.co/colbert-ir/colbertv2.0",
            "createdAt": "2025-05-01T06:06:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2844169652",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pjiTN",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu this all sounds fantastic. What are the immediate steps you will take to complete the issue?",
            "createdAt": "2025-05-01T11:17:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2844665037",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pjnIH",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have transformed the block level text with truncate using representLM, saved in parquet. I did this for unique texts of the 47k reports dataset, it takes about 30gb. I will reorganize the data and upload them to dropbox later. ",
            "createdAt": "2025-05-01T11:36:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2844684807",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pkecO",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu amazing! Sounds like all our data will be around 120GB",
            "createdAt": "2025-05-01T14:07:16Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2844911374",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6po6HI",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@ChernXiangyu, this looks great! I\u2019d be happy to help code up one of the embedding models you mentioned\u2014feel free to let me know which one you haven\u2019t tried yet, and I can take it on. We can definitely discuss the details further, or if you have any existing code, I\u2019d be glad to take a look and build on that. Thanks~",
            "createdAt": "2025-05-02T00:45:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2846073288",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6po-E5",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@oliverwang266 If you have access to Booth's H100 you can test the large NV-Embed model. It probably needs ~30G VRAM and my machine and grid can not run it. The sample code is in its web page.",
            "createdAt": "2025-05-02T01:05:18Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2846089529",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6psGsT",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Embeddings have been uploaded to `Finance and Development/data/derived/reports/lseg/47k/represent_lm_embeddings`, they are in .parquet format and have three columns : ['text_id', 'text', 'embeddings']. I have also tested Chroma but it is relatively slow, I think we should stick to this simple method for now.",
            "createdAt": "2025-05-02T10:44:24Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2846911251",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pszhW",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu fantastic idea... @oliverwang266 please take advantage of Booth's awesome resources. @ChernXiangyu if you feel like troubleshooting optimizing, we can ask the RCP to include the launcher with 4 H100s...",
            "createdAt": "2025-05-02T12:30:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2847094870",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6ps3JN",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I think we could test it with RCP, maybe with the current L4 GPU first. In https://huggingface.co/nvidia/NV-Embed-v2, they provide code for multi-GPU execution using DataParallel, which replicates the entire model on each GPU and splits the input batch across them. This doesn't allow splitting a single large model across GPUs, so it may not work on the current L4 GPU setup if the model exceeds single-GPU memory (which is 24G, but larger than my own 16G GPU).",
            "createdAt": "2025-05-02T12:38:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2847109709",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ptLGa",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu It might be worth trying for an hour so we can get a sense of cost and effectiveness!",
            "createdAt": "2025-05-02T13:21:52Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2847191450",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pu6i7",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thanks all! \n\n@ChernXiangyu how did you handle context windows for the current RepresentLM embeddings? Did you truncate the full text? \n\nFor exploratory analysis with the embeddings, it would be helpful to have both\n1. embeddings of the truncated text\n2. mean pool embeddings over the entire document (see example below, feel free to modify)\n\nAs far as embedding models, it would be helpful to have both\nA. RepresentLM-v1\nB. A modern model of similar size, for example BAAI/bge-large-en-v1.5\nC. A modern, long-context model of similar size, for example Alibaba-NLP/gte-large-en-v1.5\n\nIt would be great to have these six dataframes ({1,2} x {A,B,C}) generated, and then we can start to do exploratory analysis with the embeddings. \n\nIn future embedding runs could you please keep track of \n1. embedding model\n2. context window strategy\n3. total documents\n4. total tokens\n5. total runtime\n\nI agree it may be worth worth prototyping the NV-Embed-v2 model for an hour on RCP. This could give us a sense of cost/token and time/token. \n\nHowever, getting to the four dataframes mentioned above seems to be enough for what we need to start doing exploratory analysis. \n\n(Side note, if we have an existing text_id-text link, no need to store full text again in each embedding dataframe.)\n\n",
            "createdAt": "2025-05-02T16:35:57Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2847647931",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pu9C0",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Example:\n\n```python\n\"\"\"\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\nEmbed arbitrarily long texts with any Hugging-Face / Sentence-Transformers\nmodel and choose between **two strategies**:\n\n    \u2022 strategy=\"truncate\"  \u2013 embed only the *first* window that fits the\n      model\u2019s context limit (fastest; 1 vector / document).\n\n    \u2022 strategy=\"chunk\"     \u2013 split the document into overlapping windows\n      that fit the context, embed each, **mean-pool** the window vectors,\n      and return one pooled, L2-normalised vector per document.\n\nReturns a `list[np.ndarray]` whose length is the number of documents.  \n\nExample checkpoints\n-------------------\n* RepresentLM/RepresentLM-v1        \u2013 512-token ctx, 768-d vectors\n* BAAI/bge-large-en-v1.5            \u2013   512-token ctx, 1 024-d vectors\n* Alibaba-NLP/gte-large-en-v1.5     \u2013 8 192-token ctx, 1 024-d vectors\n\"\"\"\n\nfrom __future__ import annotations\nfrom typing import List, Literal\nimport numpy as np\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoConfig\n\n\ndef _sliding_windows(token_ids: List[int], size: int, overlap: int):\n    \"\"\"Yield overlapping slices of token IDs (inclusive of last partial).\"\"\"\n    step = size - overlap\n    for start in range(0, len(token_ids), step):\n        yield token_ids[start : start + size]\n\n\ndef embed_texts(\n    texts: List[str],\n    model_id: str,\n    context_length: int | None = None,\n    strategy: Literal[\"truncate\", \"chunk\"] = \"truncate\",\n    chunk_size: int | None = None,\n    overlap: int = 50,\n    batch_size: int = 32,\n    normalize: bool = True,\n    device: str | None = None,\n    trust_remote_code: bool = True,\n):\n    \"\"\"\n    Parameters\n    ----------\n    texts : list[str]\n        Documents to embed.\n    model_id : str\n        Hugging Face repository (e.g. \"BAAI/bge-large-en-v1.5\").\n    context_length : int, optional\n        Model's token limit; auto-read from config if None.\n    strategy : {\"truncate\", \"chunk\"}, default \"truncate\"\n        \"truncate\" \u2192 embed first window only.  \n        \"chunk\"    \u2192 embed all windows then mean-pool.\n    chunk_size : int, optional\n        Window length (\u2264 context_length).  Defaults to context_length\u221232.\n    overlap : int, default 50\n        Token overlap between consecutive windows for \"chunk\".\n    batch_size : int, default 32\n        Batch size during encoding calls.\n    normalize : bool, default True\n        Apply L2 normalisation to every returned vector.\n    device : {\"cuda\", \"cpu\"} | None\n        Auto-detect if None.\n    trust_remote_code : bool, default True\n        Needed for models with custom layers (e.g. GTE).\n\n    Returns\n    -------\n    list[np.ndarray]\n        One vector per input document.\n    \"\"\"\n    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # 1 \u00b7 Model & tokenizer ----------------------------------------------------\n    model = SentenceTransformer(\n        model_id, device=device, trust_remote_code=trust_remote_code\n    )\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_id, trust_remote_code=trust_remote_code\n    )\n\n    if context_length is None:\n        cfg = AutoConfig.from_pretrained(\n            model_id, trust_remote_code=trust_remote_code\n        )\n        context_length = getattr(cfg, \"max_position_embeddings\", 512)\n\n    chunk_size = chunk_size or max(32, context_length - 32)\n\n    result_vectors = []\n\n    # 2 \u00b7 Per-document embedding ----------------------------------------------\n    for text in texts:\n        ids = tokenizer.encode(text, add_special_tokens=False)\n\n        # ---------- Strategy: TRUNCATE ---------------------------------------\n        if strategy == \"truncate\":\n            window_ids = ids[:chunk_size]\n            vec = model.encode(\n                tokenizer.decode(window_ids),\n                normalize_embeddings=normalize,\n                batch_size=1,\n                show_progress_bar=False,\n            )\n            result_vectors.append(vec)\n            continue\n\n        # ---------- Strategy: CHUNK (mean-pool) ------------------------------\n        windows = (\n            [ids]\n            if len(ids) <= chunk_size\n            else list(_sliding_windows(ids, chunk_size, overlap))\n        )\n        window_texts = [tokenizer.decode(w) for w in windows]\n        window_vecs = model.encode(\n            window_texts,\n            batch_size=batch_size,\n            normalize_embeddings=normalize,\n            show_progress_bar=False,\n        )\n\n        pooled = np.mean(window_vecs, axis=0)\n        if normalize:\n            pooled /= np.linalg.norm(pooled)\n        result_vectors.append(pooled)\n\n    return result_vectors\n\n\n# --------------------------------------------------------------------------- #\n# Quick demo when run directly                                                #\n# --------------------------------------------------------------------------- #\nif __name__ == \"__main__\":\n    docs = [\n        \"Solar capacity is set to triple by 2027, says the IEA.  Prices \u2026\",\n        \"Apple\u2019s Q2 earnings beat expectations, driven by services revenue \u2026\",\n    ]\n\n    # chunk-mean-pool with RepresentLM\n    rep_vecs = embed_texts(\n        docs,\n        \"RepresentLM/RepresentLM-v1\",\n        strategy=\"chunk\",\n        context_length=512,\n        overlap=50,\n    )\n```",
            "createdAt": "2025-05-02T16:41:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2847658164",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pwmuP",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@suproteemsarkar thanks a ton!",
            "createdAt": "2025-05-02T20:45:46Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848091023",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pxn7x",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @suproteemsarkar I am using the first 512 tokens of each text block (they are bboxes detected by the document layout analysis model)\n\nI will generate the 2*3 data frames using the sample code, remove the text column and keep track of the points above. Thanks!",
            "createdAt": "2025-05-03T01:52:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "ROCKET",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848358129",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pycyr",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@suproteemsarkar I have counted the tokens using the three tokenizer and saved the result to `Finance and Development/data/derived/reports/lseg/47k/id2token_count.parquet`, columns are ['text_id', 'token_count_RepresentLM-v1', 'token_count_bge-large-en-v1.5', 'token_count_gte-large-en-v1.5'], and we could use it to compute total tokens, tokens per document, etc after rematching it with the original data (they are in `full` or `structure` folder).\n\nA small problem, the code above is mapping texts to vectors sequentially (one by one) and is relatively slow, it will take about 54 hours for one dataframe according to `tqdm`. I will first get the truncated version using the original `.encode` function. For sliding window version, I plan to:\n- Only compute for the texts longer than token limits using the code above (There may be some subtle differences because the code to generate them are different)\n- Try to optimize the sliding window code and recompute for the whole dataset\n    - I have some experience in using sliding window for classification tasks so hopefully we could make it\n    - If this is difficult we will use the above code to recompute embeddings for the whole dataset\n    - However, I found this issue saying that using sliding window may not be a very good idea: https://github.com/UKPLab/sentence-transformers/issues/1799 , so maybe our final strategy will be chunk the texts at first (like many RAG systems) instead of chunking token lists, like chunk, explode, add a `chunk_id` and then encode.",
            "createdAt": "2025-05-03T11:10:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848574635",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pyouP",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@suproteemsarkar and @ChernXiangyu excuse my ignorance, but what is the optimal number of tokens for creating an embedding? My prior is that it would be much smaller than 512 and that perhaps the sentence level is better? Though, I recognize capturing the relationship among sentences is important too...",
            "createdAt": "2025-05-03T13:13:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848623503",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6py1tV",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I think any text within the token limit is okay.\n\nWhile sentence-level embeddings is good, but there will be tons of vectors and storing and searching them will become a problem:\n- An embedding for a 512-token text takes up the same space as that for a single token\n- Because we have more vectors, if we want to compute the similarity between all the vectors and a query, it will take more time.\n- If we want to use vector database to accelerate searching:\n    - Inserting a large number of such embeddings into Chroma is difficult because inserting will become slower and slower (because it need to build index to accelerate searching)\n    - Vector search will also become less efficient as the number of stored vectors increases (depends on the algorithm, tradeoff between precision and speed)\n\nThe problem of inserting and searching for large amount of vectors may be solved by switching to other vector databases (but they are not as easy to use as Chroma) and use better machine. But in general it depends on the amount of data. For block-level 47k data we have already met some of the problems above but they are not very big.\n\nSmall notes: Chroma is doing a really bad job when trying to compute the similarity between a vector and all the vectors in it (vector database does not work by accelerating matrix operations, but by building index + approximation, so we chose to use the simple .parquet + numpy), while doing a great job when trying to \"retrieve the top100 vectors similar to a vector\".",
            "createdAt": "2025-05-03T15:32:50Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848676693",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6py9jg",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thanks, @ChernXiangyu. \n\nGreat idea to start with embeddings of the truncated documents (e.g. first 512, 4096 depending on model) \n\nI like the idea of optimizing the sliding window code. You could consider using a character window to split the initial text, for example character_window = avg_tokens_per_character * context_length - correction, where avg_tokens_per_character = 5 and correction = 100. Then you can tokenize the split texts, and take the mean pool of all tokenized texts.\n\nI think it's helpful to get a sense of how much we need to account for longer texts. Could you create (1) a histogram and (2) summary statistics (e.g. mean, median, 25th percentile, 75th percentile, range) of the number of characters per text?\n\nAgreed that we can put vector DBs on backlog for now. Parquet should be enough for what we want to do at the initial stage.\n\nLet me know if I can clarify anything here.",
            "createdAt": "2025-05-03T16:49:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2848708832",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6p0Iz3",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@suproteemsarkar Here is the distribution of character counts:\n\n![Image](https://github.com/user-attachments/assets/94128354-4ef9-4e6f-8268-ee12f9e8e67a)\n\nThe image above limits x-axis to 99th percentile for visibility\n\nNote: Equal Sum Point (ESP) is the character count threshold where the total number of characters in documents shorter than ESP equals the total number of characters in documents longer than ESP.\n\nSummary Statistics for Character Counts:\ncount    6.084391e+06\nmean     2.914148e+02\nstd      6.018090e+02\nmin      0.000000e+00\n50%      1.240000e+02\nmax      1.594000e+04\nName: char_count, dtype: float64\nRange: 0 - 15940\nEqual Sum Point: 635.00 (Sum before = Sum after \u2248 886540937.50)\n\nThe three models seem to be using the same tokenizer (BertTokenizer), I have also plotted the distribution of number of characters per token:\n\n![Image](https://github.com/user-attachments/assets/32142997-d664-4ddc-bb68-b0f9e877b959)",
            "createdAt": "2025-05-04T05:28:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2849017079",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6p1Obi",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thanks, @ChernXiangyu. This is incredibly helpful.\n\nGiven how short the texts are, sliding window embeddings are not a priority now. We can revisit sliding windows later if we end up concatenating texts.\n\nLet's stick with the three embeddings of the truncated documents for now. Once this is completed, let me know and I can sketch out some exploratory analysis with the embeddings.",
            "createdAt": "2025-05-04T16:30:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2849302242",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6p67b7",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @suproteemsarkar @MaxMillerLab We have finished the truncated version of embeddings. I used RCP and results are stored in data/embeddings, so we need to contact HBS to move them to our project space. Thanks!\n\nFor the computing time, it varies across models, and I used 4 L4 24G GPUs in parallel:\n\n- RepresentLM/RepresentLM-v1: 1.9h\n- BAAI/bge-large-en-v1.5: 4.3h\n- Alibaba-NLP/gte-large-en-v1.5: 17.95h\n\ngte-large-en-v1.5 is significantly slower may because it has longer context window.\n\nI used 3 csv files to record the exact time for each part: [time.zip](https://github.com/user-attachments/files/20036167/time.zip)\n\n\n\n\n\n\n\n\n\n\n",
            "createdAt": "2025-05-05T12:12:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2850797307",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6qlR_T",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I noticed that a ColBERT model [[GTE-ModernColBERT-v1](https://huggingface.co/lightonai/GTE-ModernColBERT-v1)](https://huggingface.co/lightonai/GTE-ModernColBERT-v1) has become the top-ranked model on the trending board after limiting the library to SentenceTransformers. ColBERT maybe useful for our task because it could create token level embeddings.",
            "createdAt": "2025-05-08T06:16:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2861899731",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6qpp6R",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu and @suproteemsarkar what are the advantages of doing things at the token versus, say, sentence or text block level? I could imagine that there could be pretty large semantic differences doing things at different levels of aggregation. For example, the bigram \"Super Bowl\" is not necessarily equal to the sum of its parts.",
            "createdAt": "2025-05-08T13:20:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2863046289",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6qreqg",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab \n- The original outputs from BERT are token-level contextual embeddings. Many embedding models apply pooling to aggregate these into a single vector representing the full sentence or paragraph.\n- ColBERT also requires inputting the full text to generate token-level embeddings, and the attention mechanism adjusts each token's representation vector based on tokens around them (shifting the raw token embedding according to the tokens around them).\n- Additionally, ColBERT incorporates engineering optimizations (like vector quantization and indexing) that make storing and searching over token-level embeddings space- and time-efficient.\n\nColBERT is still relatively new, and only a small number of embedding models start using this approach so far. Sentence-level embeddings remain the most widely used in practice.",
            "createdAt": "2025-05-08T15:45:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2863524512",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6qvbcp",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu thanks for the explanation!",
            "createdAt": "2025-05-08T22:19:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2864559913",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6rNZ6M",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu how is this coming along? @suproteemsarkar everything looking good on this as far as you can tell?",
            "createdAt": "2025-05-12T12:43:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2872417932",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6rN7-x",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab HBS have downloaded the data to the project space and embedding data is stored in `/export/projects4/mmiller_emrisk/embeddings`\n",
            "createdAt": "2025-05-12T13:21:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2872557489",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6riR7S",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu can we move this to `derived/embeddings`?",
            "createdAt": "2025-05-13T20:41:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2877890258",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6rtE6i",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have moved embeddings to derived. And a small thing is that I can not move `ner-data`: \n\n<img width=\"322\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/065d97b1-aa6d-4e08-b197-a10ee175395f\" />",
            "createdAt": "2025-05-14T15:43:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2880720546",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6rxycs",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I think I have to change the group. Let me look into it.",
            "createdAt": "2025-05-15T01:25:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2881955628",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6r4_dr",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I just moved it over. It's in `derived/ner_data`.",
            "createdAt": "2025-05-15T13:35:28Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2883843947",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6sK04V",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu after you check output, we're finished with this task, right? @suproteemsarkar we should create a separate issue to create the \"Figure 1\" you and I talked about",
            "createdAt": "2025-05-17T18:07:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2888519189",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6tHplm",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu can you please let me know what is remaining on this task?",
            "createdAt": "2025-05-23T13:40:13Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2904463718",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6tO2pK",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I think @oliverwang266 will test the largest NV-Embed model  (https://huggingface.co/nvidia/NV-Embed-v2) using the H100 from Booth, it has 32k input token limit which could solve the truncating problem.",
            "createdAt": "2025-05-24T03:37:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2906352202",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6t1Tbp",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu can we close this issue and create a new issue for this? Also, in closing out this issue and in the new issue, please abide by the [guide in the lab manual](https://github.com/MaxMillerLab/lab_manual/wiki/Working-on-issues-in-Github).\n\n> Hi [@MaxMillerLab](https://github.com/MaxMillerLab) I think [@oliverwang266](https://github.com/oliverwang266) will test the largest NV-Embed model (https://huggingface.co/nvidia/NV-Embed-v2) using the H100 from Booth, it has 32k input token limit which could solve the truncating problem.\n\n",
            "createdAt": "2025-05-28T13:48:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2916431593",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6t1gxe",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Will check the manul and open the new issue",
            "createdAt": "2025-05-28T14:04:59Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2916486238",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6t4hIn",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hey @ChernXiangyu and and @oliverwang266 thanks for the update! Good idea to try the NV-Embed-v2 on a Booth H100. Keep us posted if you run into issues",
            "createdAt": "2025-05-28T18:40:04Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2917274151",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6u8rax",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu flagging this... I think we should be able to close it out. Please create the issue markdown and point me to it. We should focus on closing things when we can...\n\n> [@ChernXiangyu](https://github.com/ChernXiangyu) can we close this issue and create a new issue for this? Also, in closing out this issue and in the new issue, please abide by the [guide in the lab manual](https://github.com/MaxMillerLab/lab_manual/wiki/Working-on-issues-in-Github).\n\n",
            "createdAt": "2025-06-03T13:04:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2935142065",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6wmLWh",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu can we run @suproteemsarkar's model for the 104K reports too?",
            "createdAt": "2025-06-11T13:43:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2962797985",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6xCwxF",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am playing with RunPod for this task but I met some problems with data transfer, passing file from dropbox to the server is not stable. It will take me another 1 day to start running for the 104k data.\n\nFor using H100, my booth account can not use Booth VPN and I don't know why, and Ema usually does not want use to bother the IT in Booth, so I will try to make the large model run on RCP's L4 card which has 24GB vram. I did some quick test before and the model can not run on it, but I think it maybe possible if we do some optimization.\n\nI think currently the SOTA embedding model is this one: https://huggingface.co/Qwen/Qwen3-Embedding-8B, it also provide 4B and 0.6B version, maybe we could test it. It is also based on LLM so it has 32k context length.\n\ncc: @suproteemsarkar ",
            "createdAt": "2025-06-13T12:49:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2970291269",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6xC7D7",
            "author": {
              "login": "suproteemsarkar"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thanks @ChernXiangyu !\n\nQuantized Qwen 8B should work with a 24GB GPU \n\nAre you using persistent storage on RunPod? rclone may help with reliability of transfer from Dropbox\n\n@MaxMillerLab let's see if we can escalate the VPN access issue to Booth? Can you check with Ema?",
            "createdAt": "2025-06-13T13:06:26Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2970333435",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6xDNz0",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@suproteemsarkar sure! I'll ask him.",
            "createdAt": "2025-06-13T13:32:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2970410228",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6xPb1i",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab @suproteemsarkar embedding data for 104k has been saved to `Finance and Development\\data\\derived\\reports\\processed\\id2vec\\LSEG_104k`, the 47k data will also be saved to this folder after doing double check for the id mapping. Also, I will clean the folders in the hbs grid project space a bit.",
            "createdAt": "2025-06-15T09:23:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2973613410",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6xpVDw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds great! Cleaning is always appreciated. And remember to provide some documentation, if possible.",
            "createdAt": "2025-06-17T13:30:58Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2980401392",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yHbMF",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab @suproteemsarkar I have managed to use Booth VPN and connected to Booth's cluster! I will read the docs and move part of our code to it to use their powerful H100 cards!",
            "createdAt": "2025-06-19T14:26:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2988290821",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6yHd8W",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu woot woot!!!",
            "createdAt": "2025-06-19T14:29:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2988302102",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yIKYt",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I think I still need some additional procedure to get this Mercury Account to get access to the H100 partition and I need to contact Ema or FMC (but I have not joined it yet). I have DMed Ema in Slack but I heard that he is in Kenya right now......\n\n![Image](https://github.com/user-attachments/assets/3929f55b-9acc-46ef-b4a4-04e94c58c6d9)",
            "createdAt": "2025-06-19T15:24:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2988484141",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6yL_-H",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu Yes this will probably need to wait until next week then. Ema is not easily reachable rn. Happy to get you some on the RCP tho!",
            "createdAt": "2025-06-20T00:39:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "ROCKET",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2989490055",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yjz1j",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Ema has replied to me and he said it is okay! I will write the email to Booth today.",
            "createdAt": "2025-06-23T09:49:28Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2995731811",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6yl9Qi",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I am uploading the adjusted 47k embedding data to dropbox, the id mapping is correct, and I drop the text column and split the data into more parts (6 parts -> 30 parts, each part ~1G), so that PC with smaller mem could read it seqentially. I will clean the RCS space later.",
            "createdAt": "2025-06-23T12:24:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2996294690",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ysUyT",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds like a plan! What kind of compression are you using in the parquet files?",
            "createdAt": "2025-06-23T21:15:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2997963923",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yueU9",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am using the default `to_parquet`, I asked Gemini and it said that it is using snappy.",
            "createdAt": "2025-06-24T02:05:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2998527293",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6yu9pL",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I am testing Mercury and here are some notes about the problems and possible solutions:\n- Storage Limitations\n    - I am using collaborator account and only have 14GB of storage space, which is even not enough for a flagship embedding model, and we also need storage space for our data.\n    - I think I will contact Ema and ask if we could create a project space on it.\n- File Transfer with Dropbox\n    - It is difficult to transfer files from Dropbox to the server because it does not support RClone like Grid.\n    - We have to transfer the file from local disk to the server using Filezilla, which is much slower\n- Management Software\n    - It is using open-sourced Slurm instead of IBM LSF which the Grid is using. I need some time to learn how to use it.\n- H100 Resource\n    - It is extremely tight in Booth because some users ofter taking all 4 available GPUs simultaneously (and they use R, I don't know what they are running), and we have to queue for not a short time (The cureent user has run it for more than 1 day with 4 H100......)\n\nI will contact Ema about the project space thing and try to solve the file transfer problem. I may also contact research support to see if they could provide RClone and other supports (I read the doc and they only provide Tensorflow instead of pytorch that we use more often).",
            "createdAt": "2025-06-24T03:16:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-2998655563",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6y4_QK",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu thanks for the update! Yes, this sounds like something Ema might be able to solve. I hope we can get full access too!!",
            "createdAt": "2025-06-24T17:21:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3001283594",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6zRHj-",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab Ema has asked other RAs to clean up the storage space. And I think the cleanning will finish in ~1 week. \n\nI have successfully run the SOTA `Qwen3-Embedding-8B` on my 48G Mac with **half precision**, it uses 36.71 GB of vram. Half precision is not a really big problem and I also used this to accelerate the embedding model before.\n\nAlso I found that Qwen has provided its official GGUF version of the model (https://huggingface.co/Qwen/Qwen3-Embedding-8B-GGUF), however, it can not run with `transformers` directly but with `llama.cpp`, I found that it provides official python package now (https://github.com/abetlen/llama-cpp-python) and I will play with it soon. I think with Q8/6/5/4 quantization (half precision could be understand as 16bit), we could run it on RCP.\n\ncc: @suproteemsarkar \n\n---\nupdate: I have tested llama-cpp-python and it is easier than I expected, I will move to RCP soon!",
            "createdAt": "2025-06-26T08:16:02Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3007609086",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6zTg2m",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu Great news! Sounds like a plan!",
            "createdAt": "2025-06-26T11:59:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3008236966",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc61I5uN",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu do we have an update on this one?",
            "createdAt": "2025-07-05T14:28:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3039009677",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc61eQ4x",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have managed to run the quantized model on RCP, currently it is slow but I will figure out how to do optimizations. `llama-cpp-python` is a new package for me so it may take more time.",
            "createdAt": "2025-07-07T11:33:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3044609585",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc619CaB",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab,  \n\nI have completed another round of testing, and I believe everything is now fully tested. We have two methods to utilize the quantized version of the large embedding model:  \n\n### 1. Using `sentence-transformer`:  \n- **Quantization with `BitsAndBytesConfig`:**  \n    - We can use `BitsAndBytesConfig` to quantize the model during loading while still outputting floating-point numbers in the final result.  \n    - This method is compatible with our previous code for small embedding models. All we need to do is add an argument in `model_kwargs` when initializing the sentence transformer model.  \n\n### 2. Using `llama-cpp-python`:  \n- **Challenges with this package:**  \n    - Unlike `sentence-transformer`, this package is not as well encapsulated, and we would need to create a new pipeline for it. Additionally, it is more difficult to use.  \n    - The environment setup is also more challenging. For example, I encountered some strange Conda issues when setting it up on my personal PC (e.g., during compilation, it failed to detect my global GCC compiler, requiring me to reinstall one within the Conda environment).  \n    - While it can directly use the quantized `.gguf` version of the model from Qwen's official release, additional parameters must be configured because the package is more primitive compared to `sentence-transformer`.  \n\n### Recommendation:  \nConsidering the trade-offs, I believe the more balanced choice is `sentence-transformer`. I have successfully set up the 4-bit quantized version on my laptop with 16GB VRAM (which is just sufficient, as VRAM is also needed to store the texts in addition to the model itself). It runs persistently without crashes. I have also learned how to set up flash attention to accelerate the process. For the 47k dataset, the processing time is estimated to exceed 100 hours, which I believe is reasonable given that the model is 20 times the smaller model we previously used. It becomes doable now and I will do further optimizations to it.",
            "createdAt": "2025-07-09T13:27:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3052676737",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc62HaKm",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have successfully run the code on RCP, I am using 4 bit quantization and the cheapest gpu model. For the 47k data it will take ~200 hours.",
            "createdAt": "2025-07-10T04:31:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3055395494",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc62I5wT",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds great! Looks like I'm about to be poor!",
            "createdAt": "2025-07-10T06:24:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3055787027",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc62I7Du",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Yeah so I am thinking if we really need to run such large model. But I will also keep an eye on how to use the computing resources in UChi.",
            "createdAt": "2025-07-10T06:25:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3055792366",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc62I_9U",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu HBS will pay for some of this too, so it's totally fine! I appreciate you coding it up and running it!",
            "createdAt": "2025-07-10T06:30:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3055812436",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc63hDLo",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu if we needed, I could ask for a P5 AWS instance... the only problem is that comes with 8 H100s... could we utilize all those?",
            "createdAt": "2025-07-16T14:36:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3078894312",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc63hKsY",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab We could test it. For my personal idea, I think we could pause this for a bit. We could first run analysis using the embeddings from smaller models. After our methods converged, let's test the larger model. I am afraid of doing this back and forth when it requires too much computing time...... We could do a quick test first and see if we could utilize all of them. This is not very difficult and we could just split the data and run them separately on different cards.",
            "createdAt": "2025-07-16T14:42:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3078925080",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc63hhpK",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I am totally fine with starting small and then going big!",
            "createdAt": "2025-07-16T14:56:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3079019082",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6437Dt",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I recently ran some stuff on Lambda labs and it was pretty cheap... It's about $3.29/hr for an H100...",
            "createdAt": "2025-07-22T08:37:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3101667565",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc66OZef",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu @suproteemsarkar - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- No start date\n- No target completion date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:48:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80#issuecomment-3124336543",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-05-01T04:50:10Z",
        "labels": [
          {
            "id": "LA_kwDOLsb5Oc8AAAABlbWw3A",
            "name": "enhancement",
            "description": "New feature or request",
            "color": "a2eeef"
          }
        ],
        "milestone": null,
        "number": 80,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Emerging markets risk"
          },
          {
            "status": {
              "optionId": "",
              "name": ""
            },
            "title": "Master board"
          }
        ],
        "title": "Convert OCR report text to embeddings",
        "updatedAt": "2025-07-27T11:48:49Z",
        "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/80"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOCAOw7w",
            "login": "ChernXiangyu",
            "name": "Xiangyu Chen"
          }
        ],
        "body": "Many reports reference multiple companies or countries. We need to identify which sections of each report pertain to specific entities.\n\n- Perform Named Entity Recognition (NER) on each text block.\n- Match the extracted entities to the metadata entities using a link transformer.\n- Apply forward-fill to assign entities to blocks where no entities are detected.",
        "comments": [
          {
            "id": "IC_kwDOLsb5Oc6o-Upf",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished the pipeline for datasets:\n- Merge tickers with reports using DCN\n- Merge block-level data with identified entities\n- Link entities with names of tickers using link transformer\n    - Only apply link transformer for reports matched with multiple tickers\n\nHere are some notes:\n- I am testing with the 47k reports, but only 3931 reports are matched with tickers (including reports with only 1 ticker)\n- For these 3931 reports, it will take 1~2 hours to merge them using link transformer (using on my Mac, probably faster on GPU), so the speed is acceptable.\n\nThe processed data will be uploaded to dropbox soon.",
            "createdAt": "2025-04-28T11:17:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2834909791",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pBMOQ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu and @oliverwang266 can you check what is going on with the other 43K? Doesn't seem like we can use the metadata if there are this many missings.",
            "createdAt": "2025-04-28T15:35:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2835661712",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pBfCk",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@ChernXiangyu Could you also provide those unmatched 43k? So I can take a look with the metadata, my guess here is that first we haven't get all the metadata, also many are not mentioning tickers in metadata. @MaxMillerLab will keep you updated on this.",
            "createdAt": "2025-04-28T15:59:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2835738788",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pN9gB",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @oliverwang266 Here is the parquet saving the unmatched reports:\n\n[unmatched_43k.parquet.zip](https://github.com/user-attachments/files/19961388/unmatched_43k.parquet.zip)\n\nHere is the notebook I used to map report_name to DCN, you can check the overlapping with it to see if there are any errors in my code. I think it is probably correct because all the DCN I got could be transformed to int:\n\n[1_data_prep.ipynb.zip](https://github.com/user-attachments/files/19961396/1_data_prep.ipynb.zip)\n",
            "createdAt": "2025-04-29T13:51:00Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2839009281",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pT09w",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @ChernXiangyu, thanks for providing this, I understand the process is correct, and I will look into the unmatched ones, my guess is that the downloading of metadata is still  processing.",
            "createdAt": "2025-04-30T00:50:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2840547184",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pU1dD",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab and @ChernXiangyu,\n\nI\u2019ve just uploaded the latest version (for metadata HBS downloaded until Apr.15th) of the matched metadata, along with the updated unmatched list and the complete set of tickers. In the previous version, some DCNs were accidentally dropped \u2014 this has now been fixed and I\u2019ve verified that everything is working correctly (the report level is not changed). Maybe we could re-run the mentions using company code~\n\n- You can find the updated files in our Dropbox at: `Dropbox\\Finance and Development\\data\\derived\\reports\\metadata`\n\n- The unmatched list in `.csv` format I shared with you directly via Slack is a drop-duplicated version of the unmatched metadata in dropbox, and is ready to be shared with the library if needed.\n\n- Out of 62,493 unique ticker_exchange combinations in the full metadata, we successfully matched 45,005 to Orbis tickers. The remaining 17,488 are not present in Orbis. I incorporate the main exchange variable in Legal_info from ORBIS to help us finding the best match.\n\nI\u2019ve also attached the relevant files here for your reference. Please let me know if you have any questions or need further clarification. Thanks!\n\n[final_unmatched_ticker_list.csv](https://github.com/user-attachments/files/19971248/final_unmatched_ticker_list.csv)",
            "createdAt": "2025-04-30T05:00:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2840811331",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pY0t2",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@oliverwang266 to be clear, the 17,000 we haven't matched were not matched using ticker-country to do the match. Is this correct? So there is some potential for more matches when we use the exchange code?",
            "createdAt": "2025-04-30T12:43:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2841856886",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pZmaP",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Sorry for the confusion, to be more specific, the ticker mentioned in the LSEG, are actually a combination of \"**ticker.exchange**\", the ticker mentioned in ORBIS are just ticker, so the 17,000 were the one not matching using simply the **ticker**, these tickers were just not appeared in the ORBIS identifiers.\n\nUsing the exchange code and country information can just help us find the best match when there is multiple matches (make the match more accurate). ",
            "createdAt": "2025-04-30T13:50:48Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2842060431",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6pdZw_",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@oliverwang266 got it! There might be another file we can match on! I think HBS library was able to find some matches",
            "createdAt": "2025-04-30T19:25:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2843057215",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6ppVXT",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab @oliverwang266 I have tested with the latest data and now we matched ~9k reports",
            "createdAt": "2025-05-02T02:30:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2846184915",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ppWnO",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@ChernXiangyu I am also curious about the matching result between the report_level_metadata and the 47k, how many can we match for this two?",
            "createdAt": "2025-05-02T02:36:16Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2846190030",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ppXkf",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@oliverwang266 About 36k, which is much larger",
            "createdAt": "2025-05-02T02:40:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2846193951",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ppZpP",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab The ratio is higher for 104k data:\n\nall_ticker: 56k\nmatched: 49k",
            "createdAt": "2025-05-02T02:51:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2846202447",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ppxR0",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@ChernXiangyu @MaxMillerLab Thanks for sending this! I think the case is for the 47k, the match are close between the all ticker and matched ticker (both 9k/47k), also I checked that all the unmatched reports (~24k) with the 47k after year 2011 do not contain ticker information, then it might be the case that many are not mention single tickers in 47k. \n\nAlso, the data and matching result looks quite reasonable for 104k. Thanks~\n",
            "createdAt": "2025-05-02T04:41:43Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2846299252",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6psxkd",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu and @oliverwang266 thanks a ton! Can you guys clarify a few things for me:\n1. What matching procedure was @oliverwang266 using?\n2. How did @ChernXiangyu improve it?\n3. Precisely what is matched and what is not matched?",
            "createdAt": "2025-05-02T12:25:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847086877",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6pszu8",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Actually I did not improve it, I just used the updated data from @oliverwang266 and used DCN to match them \ud83d\ude02 For DCN, it is at the end of the report name and also a column of the processed metadata.",
            "createdAt": "2025-05-02T12:30:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847095740",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ps0so",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu fantastic! And is this the number of reports with a match or where all tickers are matched?",
            "createdAt": "2025-05-02T12:32:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847099688",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6ps7n9",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab, here is the clarification:\n\nThis is the process of matching of GPT results of our reports (**47k** and **104k**) with the all metadata we are getting from HBS now. Since for the company-level metadata, I explode on tickers, and we have two files, one is `all_ticker_metadata`, the other is `matched_ticker_metadata`, which means **matched with ORBIS and have a BvD ID number** for each ticker.\n\n1. The matching procedure of this two is just extract the DCN from reports name, and match with the metadata\n2. Precisely, for the 47k reports we get, we match 9k with the all_ticker_metadata, and also 9k match with the matched_ticker_metadata, which means around 9k reports are matched with BvD ID number.\n3. For the 104k reports, we match 56k with the all_ticker_metadata, and 49k with the matched_ticker_metadata.\n\nAlso, I verified that all the unmatched, are either because the metadata we have for now is just date back to 2011, but the actual reports we have in 47k/104k are back to 1980s, or because this reports do not mention tickers in metadata (nan in column Prim. Ticker and Second. Ticker)\n\nHere is a quick picture for better understanding the case, thanks for taking a look!\n\n![Image](https://github.com/user-attachments/assets/f211fe5e-e9b4-4c06-bd94-4cc1b5c8d8b2)",
            "createdAt": "2025-05-02T12:49:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847128061",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ps73P",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab They are reports with matched tickers (which means matched with entity names), 9k/47k and 49k/104k\n\nUpdate: I think the above image is clearer",
            "createdAt": "2025-05-02T12:49:58Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847129039",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ptBah",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have discussed with @oliverwang266 and he will also do the matching between report and metadata, so that we could report the match ratio more rapidly and improve efficiency, and I will focus on how to match the NERed entity names with tickers.",
            "createdAt": "2025-05-02T13:02:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847151777",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ptZ3w",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@oliverwang266 got it! And the 47K is the original 47K equity reports? Do we know why we match so few on the first 47K?",
            "createdAt": "2025-05-02T13:46:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847251952",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6ptbS2",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yes @MaxMillerLab  they are the original 47k reports and the reason is that either some of them are out of the year range we have now (2011-2025) or in metadata, there is no information in both Prim ticker column and Second ticker column. ",
            "createdAt": "2025-05-02T13:48:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2847257782",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6qYaIg",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu and @oliverwang266 where do we stand on this? As I see it, we should be able to do this very well in two cases:\n1. Single ticker reports;\n2. Multiple ticker reports where all tickers have been merged with Orbis/other sources.\n\nCan we prepare the data in those cases and see what portion of the data that covers?",
            "createdAt": "2025-05-07T13:05:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2858525216",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6qyghg",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Sure! I think we can rename this issue, since we already have one focused on single-entity reports (**Issue-82**). This one can instead be dedicated to handling multi-entity cases\u2014that is, reports involving multiple countries and/or multiple tickers.\n\nAs discussed with @ChernXiangyu, I\u2019ll exclude the previously identified single-entity reports and generate a multi-entity version. Once done, I\u2019ll upload the results to:\n`Dropbox\\Finance and Development\\data\\derived\\reports\\metadata\\multiple_entity`.\nFor the portion, the structure of files in single entity folder and multiple entity folder are as follows:\n\n**1. Single country:**\n\n- single_country_reports_merged_47k.parquet (3k rows)\n- single_country_reports_merged_104k.parquet (40k rows)\n\n**2. Single ticker:**\n\n- single_ticker_reports_merged_47k.parquet (242 rows)\n- single_ticker_reports_merged_104k.parquet (23k rows)\n\n**3. Multiple country:**\n\n- multiple_country_reports_merged_47k.parquet (19k reports)\n- multiple_country_reports_merged_104k.parquet (30k reports)\n\n**4. Multiple ticker:**\n\n- multiple_ticker_reports_merged_47k.parquet (9k rows)\n- multiple_ticker_reports_merged_104k.parquet (25k rows)",
            "createdAt": "2025-05-09T06:57:59Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2865367136",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6rA386",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@oliverwang266 fantastic! I agree. Now that we have the other issue, we can focus solely on multiple entity reports here!",
            "createdAt": "2025-05-10T19:58:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2869133114",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6riY_I",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu how many text blocks do we have for the multi-entity reports? It would be good to get a sense of the cost of GPTing all of these.",
            "createdAt": "2025-05-13T20:54:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2877919176",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6rs-No",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab Here are the stats:\n\n\u2014 47k \u2014\nTotal unique DCN codes: 46,467\nTotal text blocks: 14,573,054\nAverage blocks per report: 313.6\n\n=== TEXT BLOCKS ===\nMulti-country blocks: 7,113,993 (48.8%)\nSingle-country blocks: 4,499,841 (30.9%)\nTotal country-tagged blocks: 11,613,834 (79.7%)\n\nMulti-ticker blocks: 3,647,519 (25.0%)\nSingle-ticker blocks: 67,872 (0.5%)\nTotal ticker-tagged blocks: 3,715,391 (25.5%)\n\n=== ENTITY COMBINATION BLOCKS ===\nBlocks from reports with both entities: 3,712,239 (25.5%)\nBlocks from reports with no entities: 2,956,068 (20.3%)\n\n=== REPORTS ===\nMulti-country reports: 17,769 (38.2%)\nSingle-country reports: 16,468 (35.4%)\nTotal country-tagged reports: 34,237 (73.7%)\nReports with no country: 12,230 (26.3%)\n\nMulti-ticker reports: 8,893 (19.1%)\nSingle-ticker reports: 241 (0.5%)\nTotal ticker-tagged reports: 9,134 (19.7%)\nReports with no ticker: 37,333 (80.3%)\n\n=== ENTITY COMBINATIONS ===\nReports with both country and ticker: 9,128 (19.6%)\nReports with no entities at all: 12,224 (26.3%)\n\n\u2014 104k \u2014\nTotal unique DCN codes: 102,385\nTotal text blocks: 33,493,785\nAverage blocks per report: 327.1\n\n=== TEXT BLOCKS ===\nMulti-country blocks: 11,733,487 (35.0%)\nSingle-country blocks: 10,405,521 (31.1%)\nTotal country-tagged blocks: 22,139,008 (66.1%)\n\nMulti-ticker blocks: 9,273,140 (27.7%)\nSingle-ticker blocks: 5,401,013 (16.1%)\nTotal ticker-tagged blocks: 14,674,153 (43.8%)\n\n=== ENTITY COMBINATION BLOCKS ===\nBlocks from reports with both entities: 14,673,948 (43.8%)\nBlocks from reports with no entities: 11,354,572 (33.9%)\n\n=== REPORTS ===\nMulti-country reports: 29,823 (29.1%)\nSingle-country reports: 40,473 (39.5%)\nTotal country-tagged reports: 70,296 (68.7%)\nReports with no country: 32,089 (31.3%)\n\nMulti-ticker reports: 24,580 (24.0%)\nSingle-ticker reports: 23,497 (22.9%)\nTotal ticker-tagged reports: 48,077 (47.0%)\nReports with no ticker: 54,308 (53.0%)\n\n=== ENTITY COMBINATIONS ===\nReports with both country and ticker: 48,076 (47.0%)\nReports with no entities at all: 32,088 (31.3%)",
            "createdAt": "2025-05-14T15:34:59Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2880693096",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6rtAPO",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "And the code to generate the stats above: \n\n[count.py.zip](https://github.com/user-attachments/files/20210487/count.py.zip)",
            "createdAt": "2025-05-14T15:37:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2880701390",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6rxyGf",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu This is definitely within the realm of stuff we could send to GPT. Could you prepare a small sample dataset? I can play around with some prompts.",
            "createdAt": "2025-05-15T01:23:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2881954207",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6sFhzM",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I will provide a complete sample for this after post processing NER results, running the harmonization for all the data, it will take some time and I plan to send this before next weekend. ",
            "createdAt": "2025-05-16T16:03:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2887130316",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6sHRsx",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu Fantastic! Thanks!",
            "createdAt": "2025-05-16T20:08:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2887588657",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6sXinO",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab \n\nI\u2019ve completed the data indexing process. Each entity extracted from the NER results has been assigned a unique ID, and I\u2019ve created a crosswalk between text IDs and entity IDs. This setup helps avoid redundant computation and improves downstream processing efficiency.\n\nThe current focus is on matching entities to countries. I have borrowed some idea from RAG: in the first stage, embeddings are used for fast multi-to-multi retrieval; in the second stage, a Cross-Encoder performs pairwise reranking to improve accuracy.\n\nReranking is necessary because the Bi-Encoder architecture with embedding + cosine similarity only captures rough semantic similarity and lacks the capacity to model fine-grained interactions between entities and candidate countries. In contrast, the Cross-Encoder jointly encodes the entity and candidate as a single input sequence, allowing the model to capture semantic alignment directly.\n\nAn initial round of results is already in place and looks promising, though further refinement is needed. I\u2019m also considering experimenting with prompt-based approaches (Like \"What countries are mentioned in the entity: \") to see if they can further improve performance.\n\nI\u2019ve also noticed that the embedding vectors for some individual entities sometimes perform poorly\u2014likely because the entities consist of only a few words. Moving forward, I plan to experiment with using the embedding of the surrounding text block for country matching instead. I\u2019ve tried a similar approach before, but not with the newer embedding models or reranking setup.",
            "createdAt": "2025-05-19T18:03:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2891852238",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6sgvV-",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab,\n\nI\u2019ve tested the reranker model, and I think we should keep the method simple and fast at this stage. So the plan is:\n\n- First, apply embedding-based methods to identify all country names, including abbreviations and alternative names.\n\n- Then, filter the results using a low cosine similarity cutoff (e.g., 0.5) to reduce computation, and apply fuzzy matching to refine the matches.\n\n- The matches we want should either have a high cosine similarity score or a high fuzzy matching score. We'll also filter fuzzy match results since some of them are clearly irrelevant.\n\nFor the final step, I\u2019ll retrieve the original context of each matched entity by linking back to the text ID. We\u2019ll feed this context into an LLM for validation check.\n\nThe overall harmonization pipeline gradually increases in accuracy and cost \u2014 starting from cheap methods (embedding, fuzzy), then reranking, and finally LLM. It works like a classification task: low-cost tools help eliminate unlikely matches, while high-cost tools help improve precision.\n",
            "createdAt": "2025-05-20T12:42:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2894263678",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6sgxdU",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "While fuzzy matching also has its own problem, I think partial_ratio or token_set_ratio is generally good, but we need to filter out short entity names to reduce bad matches.\n\n<img width=\"597\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/454833f8-c3ec-467d-809e-cc51a00db663\" />\n\n<img width=\"676\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/54180f29-e19c-4092-9a45-b2ab78b2e2c8\" />",
            "createdAt": "2025-05-20T12:45:33Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2894272340",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6siXsG",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu provided these are mostly type I errors, we can use GPT to check each of the matches. How many are there? Remember with nano it is around $10/million, mini $40/million, and full 4.1 about $110/million",
            "createdAt": "2025-05-20T14:41:57Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2894691078",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6siYp8",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu another solution would be to train our own NER for country recognition... I have some code that does this in another project if it would be helpful...",
            "createdAt": "2025-05-20T14:43:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2894695036",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6svibh",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am also thinking about trying other NER models, but I will finish the current pipeline first and make the model part replaceable.",
            "createdAt": "2025-05-21T14:18:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2898142945",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6tHKoi",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds good. Let me know when and if you want me to share the GPT batch code. I also wrote it so that we can allow for striding windows (if you want them).",
            "createdAt": "2025-05-23T12:55:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2904336930",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6t1R-d",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@oliverwang266 and @ChernXiangyu could you please provide an update on this when you get a chance?",
            "createdAt": "2025-05-28T13:46:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2916425629",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6t1TPb",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have finished my thesis presentation and will be back to work soon. Hopefully I could provide the block-country matches tomorrow.",
            "createdAt": "2025-05-28T13:48:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2916430811",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6uD9EG",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished the code, I will provide the final data and the cleaned code tomorrow (I found a bug in the entity matching strategy so it is a bit late).\n\n<img width=\"1392\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ca834dd6-6acc-4255-9cd0-54d1cc224816\" />\n\n(error free EIU results above)",
            "createdAt": "2025-05-29T18:45:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2920272134",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6uEWgg",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu amazing! Thanks a ton!",
            "createdAt": "2025-05-29T19:29:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2920376352",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6uHe3T",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I've finished processing all the data, and you'll find it saved in `Dropbox/Finance and Development/data/derived/reports/processed`. Our saving strategy is oriented the unique `text_id`.\n\nHere's a breakdown of the files in the folder:\n- `structure`: Contains the original block data, including report name, label, and `text_id` (it could reappear here).\n- `id2text`: Stores unique texts mapped to their respective text IDs, optimizing disk space.\n- `id2score`: Maps computed scores to text IDs.\n- `id2country`: Contains the mapping between text IDs and named entity recognized (NER) entities, specifically those identified as countries, along with their matched countries.\n\nTo use the data, read structure first and merge with other data on `text_id`. Block level data is too big and we have to drop the texts when using it to do regression or other operations. I have checked the mappings again and now I think there are no errors.",
            "createdAt": "2025-05-30T04:30:39Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2921197011",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6uLi_e",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu amazing!! We will start using these soon!",
            "createdAt": "2025-05-30T12:26:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2922262494",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6v86ed",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I am testing using LLM to partition report by countries.\n\nMy current method is:\n- Input the report in json, containing page, order (reading order of the text block in the page) and text\n- Ask the LLM to provide start, end and countries\n\nSome notes:\n- 4.1-nano is too stupid to complete this task so I am currently using 4.1-mini\n- I prompt the LLM that all the start-end should cover the whole report, which provides a **partition** for the report.\n- Some blocks are not about only one country\n\n\nSample input:\n\n[{'page': 0,\n  'order': 0,\n  'label': 'SectionHeader',\n  'text': 'ASEAN\\nFirst to Market\\n'},\n {'page': 0,\n  'order': 1,\n  'label': 'SectionHeader',\n  'text': 'J.P. Morgan\\nTop Stories\\n'},\n...\n]\n\nSample output:\n\n[CountrySection(start=[0, 0], end=[0, 5], country='Philippines'),\n CountrySection(start=[0, 6], end=[0, 13], country='Indonesia'),\n CountrySection(start=[0, 14], end=[0, 16], country='Malaysia'),\n CountrySection(start=[0, 17], end=[0, 36], country='Other'),\n CountrySection(start=[0, 37], end=[1, 0], country='Other'),\n CountrySection(start=[1, 1], end=[1, 5], country='Singapore; Thailand; Indonesia; Philippines; Malaysia'),\n CountrySection(start=[1, 6], end=[1, 9], country='Philippines'),\n CountrySection(start=[1, 10], end=[1, 11], country='Indonesia'),\n CountrySection(start=[1, 12], end=[1, 22], country='Malaysia'),\n CountrySection(start=[1, 23], end=[1, 24], country='Indonesia'),\n CountrySection(start=[1, 25], end=[1, 26], country='Malaysia'),\n CountrySection(start=[1, 27], end=[1, 29], country='Indonesia; Malaysia'),\n CountrySection(start=[1, 30], end=[1, 33], country='Other'),\n CountrySection(start=[1, 34], end=[2, 0], country='Other'),\n CountrySection(start=[2, 1], end=[2, 5], country='Philippines; Indonesia'),\n CountrySection(start=[2, 6], end=[2, 7], country='Malaysia'),\n CountrySection(start=[2, 8], end=[2, 9], country='Thailand'),\n CountrySection(start=[2, 10], end=[2, 12], country='Indonesia; Philippines'),\n CountrySection(start=[2, 13], end=[2, 14], country='Philippines; Indonesia'),\n CountrySection(start=[2, 15], end=[2, 16], country='Singapore'),\n CountrySection(start=[2, 17], end=[3, 0], country='Other'),\n CountrySection(start=[3, 1], end=[3, 3], country='Indonesia'),\n CountrySection(start=[3, 4], end=[3, 4], country='Malaysia'),\n CountrySection(start=[3, 5], end=[3, 6], country='Philippines'),\n CountrySection(start=[3, 7], end=[3, 8], country='Singapore'),\n CountrySection(start=[3, 9], end=[3, 10], country='Thailand'),\n CountrySection(start=[3, 11], end=[5, 3], country='Other')]\n\nAfter some simple postprocess all the blocks will be allocated with countries.",
            "createdAt": "2025-06-07T06:54:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2951980957",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6v_9Oc",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds like a reasonable plan and shouldn't be too expensive... maybe $50-100/million requests. Have you run on a sample yet so that we can get an idea of cost?",
            "createdAt": "2025-06-07T17:19:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2952778652",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6wCHyu",
            "author": {
              "login": "oliverwang266"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab @ChernXiangyu \nSure! I am creating separate parquet file for different entity groups, and will link them to country/company. Thanks~",
            "createdAt": "2025-06-08T01:05:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2953346222",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6wCk65",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am inputting report by report, so it is relatively fast and cost efficient.\n\nI am using structured output, so the cost is more difficult to estimate by counting tokens, so I will directly use my account to process some and check the total cost later. I will also try to make this code compatible with batch API using your code.",
            "createdAt": "2025-06-08T03:04:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2953465529",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6xmvhX",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have updated the code for this task, specifically, I updated the code in `source\\lib\\PdfNLP\\OpenAIwrapper`, now it fits the latest openai package, and supports structured output and running in parallel. I have also updated the code saving structure so that it is more flexible and could run for multiple task (risk classification, country extraction).\n\nI will estimate the cost for running this for the whole 47k + 104k datasets later, and hopefully start running this for the whole dataset tomorrow. \n\nBtw, I also want to add support for Gemini API, but it will take some time. I am thinking of using langchain (because it provides a unified intermediate api for different models) and I will test it later. If it is convinient and fast we will probably use it.",
            "createdAt": "2025-06-17T09:56:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2979723351",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6xvOeZ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I have some code to query various APIs using LangChain if you want to use it. I have it setup to run in parallel too. Happy to send it over!",
            "createdAt": "2025-06-17T21:55:12Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2981947289",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yN7Uh",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am listening to a seminar from Xiong Wei, and I have some another ideas about how to do this. They only use GPT to do information extraction and summarization.\n\nFor our projects, I think we could try to input the whole report into some models with really long input context, and prompt it to write a summary for each country with a label. **This could help split the content about different countries.** Then we could also label these summarize manually or use tradtional analysis methods. I think this may help reduce look ahead bias because we only ask GPT to do extraction and summarization.",
            "createdAt": "2025-06-20T06:50:42Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2989995297",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ycPc9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I like this idea a lot! And with the HBS enterprise account we can do this with the reports without violating the DUA. Which GPT model would be best suited for this? Doesn't 4.1 allow for very large context windows?",
            "createdAt": "2025-06-21T20:01:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2993747773",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6yjyjU",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab Sorry I paused this for a while because I was working on some graduation stuff, and all the things will end on 6.25.\n\n- For the previous country-partition method, running it for the 47k data will cost ~$500 (Sorry I have a wrong estimation before), do you think this is doable? I think we could test this on 1%~10% of the reports and try to run some analysis. \n- For the new summarize-by-country method, this will cost more becasue GPT need to output more tokens.\n- We have to use 4.1-mini becasue nano is too stupid to finish our task, **while I think I will do some further test with nano and 4omini**, this could help to make the cost /4.\n- If this is too costly, we could go back to the NER + embedding (hand-written linktransformer) method, which is free and pretty quick and flexible. We have already created block level country matches for reports except world bank, and adding it will be pretty quick. (@oliverwang266 has done this for report level, I will check his code to see if I could integrate his code with mine)",
            "createdAt": "2025-06-23T09:48:01Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2995726548",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6ysV10",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I'm totally fine with this! But, can we wait until 7/1 to run it? I'm currently out of research budget ;). After 7/1, I have money to run this.",
            "createdAt": "2025-06-23T21:16:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-2997968244",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6z5WgF",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I think we can run this now. I have money again!",
            "createdAt": "2025-06-30T07:52:52Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3018156037",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc6z7O1Q",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Will start running this soon! I will first run them on a some portion (1%~5%) of the dataset and check them manually, and we could decide the method to use after that.",
            "createdAt": "2025-06-30T10:36:38Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3018648912",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc6z9S0U",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds like a plan! Maybe you can check a few randomly and code up some tests using the manual results?",
            "createdAt": "2025-06-30T13:35:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "EYES",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3019189524",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc61bq-L",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished running the country partition/summary code and the results are saved in `/Users/chenxiangyu/Dropbox/Finance and Development/data/derived/reports/processed/gpt_country`, I ran this using 2 models, 4.1 mini and 4.1 nano. For these excel files:\n- country_partition and country_summaries are raw outputs from GPT\n- country_merged are original blocks assigned with countries, using the information in country_partition\n\n\nMy comments on the result:\n- After merging the country partition result back to the original blocks, I found that the accuracy is not as high as expected. And the sometimes the partition result can not cover all the blocks...... I think this is because creating texts to really structured partitions is a bit difficult for LLM.\n- Summaries look better but they are not original texts.",
            "createdAt": "2025-07-07T08:15:58Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3043929995",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc61dGWQ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu could we try with 4.1 and see if it does better? It's a bummer that this isn't working.",
            "createdAt": "2025-07-07T10:08:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3044304272",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc61dXW3",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Will test on gpt 4.1 and try other prompts, this is only the first version and I think we could improve it.",
            "createdAt": "2025-07-07T10:29:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3044373943",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc61fZqa",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu for sure. We can pay for a more expensive model if we are confident it will work!",
            "createdAt": "2025-07-07T12:43:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3044907674",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc61pgc4",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Quick updates on the improvements:\n- I think the problem is that using (page, order) is a bit complicated\n- So I replace it with a simple `index`, indicating the block's order in the whole report\n\nThe results become better, but for nano model there are still many missing values. I have also tested the full 4.1, I think the accuracy is slightly better than mini, while the current mini results are usable.\n\nOther adjustments:\n- Ask the llm to use ISO3 instead of country names, which would make the results easier to harmonize\n- For blocks about a region, ask llm also to provide the crresponding countries discussed (eg. 'European Union|FRA|DEU|ITA'). So that the llm won't just return the region name like EU.",
            "createdAt": "2025-07-08T06:36:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3047556920",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc61qWK3",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu this sounds like a great improvement!!",
            "createdAt": "2025-07-08T07:54:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3047776951",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc627aUv",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I have made some additional improvements to the partition method, but there are still some problems like text about regions/multiple countries, and general texts like disclosures. We could discuss this in the meeting. \n\nFor the summary method, I have also make the country summaries more structural, here is an example: \n\n<img width=\"1072\" height=\"1308\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8b4528e9-70ff-4299-a236-c6689ad40ba8\" />",
            "createdAt": "2025-07-14T11:07:17Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3069027631",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc62-21o",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu sounds good! I'm excited to discuss tomorrow!",
            "createdAt": "2025-07-14T15:00:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3069930856",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc63MB2j",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I am playing with the GPT generated data (100 reports subset) and it looks interesting, just a quick inform and I will focus on cost estimation soon. The estimation 3 weeks ago is ~$500 for partition method, 47k data, and I will estimate the cost of summary method this week.\n\n<img width=\"1990\" height=\"790\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/697e5114-a2db-44a0-a58f-7f03b810d268\" />\n\n<img width=\"1487\" height=\"790\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3f5789ac-381d-4b21-a50f-6a37bc902612\" />\n\n<img width=\"1366\" height=\"790\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/208f2ba6-af27-4242-a1c4-13dab4c6a6ec\" />",
            "createdAt": "2025-07-15T12:19:42Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3073383843",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc63ddOb",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu very cool! Excited to potentially get the data. And yes, please let me know about cost as you figure it out!",
            "createdAt": "2025-07-16T10:32:16Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3077952411",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc63w1z6",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab Here is the estimated cost based on the 100 reports random sample:\n\n- For summarization method:\n     - 100 reports cost $1.27\n     - 47052 reports will cost $597\n\n- For partition method:\n     - 100 reports cost $1.19\n     - 47052 reports will cost $561\n\nThe model I am using is GPT 4.1 mini. The output from nano is barely acceptable, it does not perform well especially when using partition method. For summarization method nano is usable but not very good (but the cost could /4).\n\nBtw, specificity score has been added to the summarization method.",
            "createdAt": "2025-07-17T08:00:42Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3083033850",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc64GBnr",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu great! Which method do you prefer?",
            "createdAt": "2025-07-18T08:47:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3088587243",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc64Kinr",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I prefer the summarization method because we get really clean data directly. However, it costs more since we have to run it on the entire dataset. I'll try the batch API with structured output to see if we can cut that cost in half.",
            "createdAt": "2025-07-18T14:57:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3089770987",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc64MQsn",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu I'm fine with summarization... we can run it on the entire 47K if you want. Totally fine if you want to run now!",
            "createdAt": "2025-07-18T17:48:38Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3090221863",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc64l17N",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished the code using batch api + structured output, and I am planning about the next steps. Will send another update on this tomorrow.",
            "createdAt": "2025-07-21T14:06:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3096927949",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc65SMr2",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Sorry for the slow progress here. I've been busy with my physical examination, picking up my visa-approved passport, and packing for my trip to the US. I'll send here an update tomorrow.",
            "createdAt": "2025-07-23T13:39:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3108555510",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc65SqZC",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "I understand @ChernXiangyu ! this is a crazy time for you!",
            "createdAt": "2025-07-23T13:49:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3108677186",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc65jUBo",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished another round of test for Batch API, and I think we will launch the final run soon.\n\nFor **Batch API**:\n- The Batch API is reasonably fast, though slower than directly parallelizing API requests. However, the performance is still acceptable.\n- Using the Batch API reduces costs by approximately half. This allows us to:\n  - Run both `summary` and `partition` methods within the same budget.\n  - Or execute two full runs with the same resources.\n\nFor **OpenAI Storage**:\n- File Size Limits: \n  - Individual files can be up to 512 MB.\n  - The total storage limit per organization is 100 GB .\n  - You can check the current storage usage for this account by visiting [OpenAI Storage ](https://platform.openai.com/storage).\n\nIf the storage space is running low, we can consider deleting unused files to free up space. All the files I currently need have already been downloaded locally, so there\u2019s no risk of losing important data for me.\n\nIf the storage is not not enough, I could implement logic to delete files immediately after they are processed. I am also thinking about how to split input data into chunks smaller than 200 MB (the limit for batch API) and upload them sequentially.\n\n\nWhat I have done:\n   - Further refined the implementation of the Batch API code.\n   - Completed the `postprocess` logic to reshape the data and merge the final results into the original `report_name`.\n\nI have run the code and processed 1,000 random reports using the Batch API. The results are available in this Excel file: \n\n[country_summaries.xlsx](https://github.com/user-attachments/files/21409095/country_summaries.xlsx)\n\nYou can check this file to get a sense of the data.\n\n   - I used the `summary` method for processing. The majority of summaries are accurate, though there are occasional omissions of less frequently mentioned countries. However, the primary countries of interest are consistently included.\n   - I did some basic analysis on the resulting data.\n\n<img width=\"1489\" height=\"390\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c6a9b3b6-47c0-4d17-92bf-6a2bd3908855\" />\n\n<img width=\"1779\" height=\"590\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4341678b-fe7a-4b1e-be23-3bceb45d9b55\" />\n\n<img width=\"1777\" height=\"1190\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/758caf20-f5d1-4d15-8137-48d9531e22a1\" />\n\n<img width=\"1990\" height=\"1490\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/05f82095-8d34-4afb-81a3-8d46bc6931e6\" />",
            "createdAt": "2025-07-24T11:06:47Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3113042024",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc65lwWL",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu this is great!! Very excited to actually run this and get the results!",
            "createdAt": "2025-07-24T14:25:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3113682315",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc65lwpv",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "I don't think we will hit 100GB on this... but I could be wrong!",
            "createdAt": "2025-07-24T14:25:23Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3113683567",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc65mmip",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I also think so, just to confirm if you have uploaded lots of files for other projects before \ud83d\ude02",
            "createdAt": "2025-07-24T15:24:15Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3113904297",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc65oVdZ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu haha I understand! Clearing out everything now!",
            "createdAt": "2025-07-24T17:59:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3114358617",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc66OOUl",
            "author": {
              "login": "ChernXiangyu"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab I have finished running the summarization method on the 47k data, using the Batch API, the results are saved in `Dropbox/Finance and Development/data/derived/reports/processed/lseg_47k_structured.parquet` and the code will be cleaned and uploaded to the repo soon.",
            "createdAt": "2025-07-27T10:26:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3124290853",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsb5Oc66OVi6",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu fantastic! It was actually under $500!",
            "createdAt": "2025-07-27T11:21:52Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3124320442",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsb5Oc66OZeY",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@ChernXiangyu - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- No start date\n- No target completion date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:48:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78#issuecomment-3124336536",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-04-28T05:42:49Z",
        "labels": [
          {
            "id": "LA_kwDOLsb5Oc8AAAABlbWw3A",
            "name": "enhancement",
            "description": "New feature or request",
            "color": "a2eeef"
          }
        ],
        "milestone": null,
        "number": 78,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Emerging markets risk"
          },
          {
            "status": {
              "optionId": "",
              "name": ""
            },
            "title": "Master board"
          }
        ],
        "title": "Identify and assign entities in multi-entity reports",
        "updatedAt": "2025-07-27T11:48:48Z",
        "url": "https://github.com/MaxMillerLab/finance_and_dev/issues/78"
      }
    ],
    "MaxMillerLab/bills": [
      {
        "assignees": [
          {
            "id": "U_kgDODNFgeg",
            "login": "calebeynon",
            "name": ""
          }
        ],
        "body": "It would be helpful to track changes to actual bill text for predicting the probability of passage. I plan on searching through some government API resources to see if this is even possible.",
        "comments": [
          {
            "id": "IC_kwDOMBPlSc64M1OY",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I've found that GovInfo has different text versions of bills available on its website. I'm writing a script to access their API right now. Given that this is successful, the script in issue #38 pulling from congress.gov will be redundant and I will just kill that. ",
            "createdAt": "2025-07-18T18:49:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3090371480",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64NekK",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Amazing!! I think they should have an API too? Let's hope they have it reasonably far back!",
            "createdAt": "2025-07-18T19:43:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3090540810",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc64Nitw",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Yes, I was able to access their API. I'm taking a two step approach here: \n1. create a script to download a json file with all possible bill versions (currently running)\n2. create a script that takes that json file as input and downloads the text of each one then outputs to a dataset for each congress. (tested and ready to run)",
            "createdAt": "2025-07-18T19:50:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3090557808",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64NvcO",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Amazing! Make sure we have the date associated with each version too. We need that to track changes in the bill text over time.",
            "createdAt": "2025-07-18T20:14:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3090609934",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc64PpRK",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Got it, date is included in the final dataset. The script to download the bill versions is now running.",
            "createdAt": "2025-07-18T22:42:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3091108938",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66OU9r",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 8 days (last updated: 2025-07-18)\n- Issue is 6 days overdue (target date was: 2025-07-21)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:17:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3124318059",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66Pyn1",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Putting this on pause while we adjust the neural network.",
            "createdAt": "2025-07-27T20:14:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3124701685",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66_uqz",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The script to download bill texts has completed running. We now have the text for bills in congresses 108 through 116. Looking a little closer, we have about 20,000 text entries for 15,000 bills in each dataset. This is in line with what I would expect, given that we know there are about 15,000 unique bill_ids in each congress. Also, most bills don't make it very far so they don't get many text versions, but a few get revisions and therefore have new text.",
            "createdAt": "2025-07-30T17:38:57Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/41#issuecomment-3137268403",
            "viewerDidAuthor": false
          }
        ],
        "createdAt": "2025-07-18T13:53:38Z",
        "labels": [],
        "milestone": null,
        "number": 41,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Bill Probability and Impact"
          }
        ],
        "title": "Search for proposed bill text history",
        "updatedAt": "2025-07-30T17:38:57Z",
        "url": "https://github.com/MaxMillerLab/bills/issues/41"
      },
      {
        "assignees": [
          {
            "id": "U_kgDODNFgeg",
            "login": "calebeynon",
            "name": ""
          }
        ],
        "body": "There are two specific columns in our data that need to be embedded to go through the neural network.\n- Bill Text\n- Title\nI need to ensure that there is no look ahead bias when choosing the model to do this. This issue is more-so for after the first neural network run, but I will work on it while the other data processes.",
        "comments": [
          {
            "id": "IC_kwDOMBPlSc62_L86",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon check out this one: https://huggingface.co/RepresentLM/RepresentLM-v1. Also, can you close #17 as a duplicate of this issue?",
            "createdAt": "2025-07-14T15:27:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3070017338",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc62_lXY",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "There is a conda environment issue when working with this model. I fixed it on my machine by updating the following packages:\nlibprotobuf: 6.31.1, protobuf: 6.31.1, libabseil 20250512.1\n\nI think this conflict would also happen for anyone cloning the repo and using the conda environment. So I can adjust the requirements file before pushing. \n",
            "createdAt": "2025-07-14T16:00:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3070121432",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc62_z9J",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Yes please do!",
            "createdAt": "2025-07-14T16:19:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3070181193",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc63Alwu",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I have a function that works on a small subset of title data. Going to try to apply to amendment title text now and see what happens.",
            "createdAt": "2025-07-14T17:30:04Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3070385198",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63BqsR",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The script is working on amendment titles, however on just the normal grid it takes a long time to run. We're talking 10 minutes for 10,000 titles. At that pace, it would take about 3 weeks to run all the titles. I'm going to adjust the script to use a gpu, that should speed it up.",
            "createdAt": "2025-07-14T19:10:07Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3070667537",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63Mag7",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I ran the gpu version of this script,`/derived/congressional_reports/embedding/embed_amendment_titles_gpu_fixed.py`, and got some output. I will be checking this output to make sure it is as expected.",
            "createdAt": "2025-07-15T12:53:04Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3073484859",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63gLnF",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Putting this on pause while building the first neural network. Will revisit when needed for a future iteration of the model.",
            "createdAt": "2025-07-16T13:36:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3078666693",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc631T9Z",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Working on the bill text embedding now since the neural network is still waiting to run on the gpu queue.",
            "createdAt": "2025-07-17T14:03:23Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3084205913",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc634Jgo",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Put a script on the grid that pulls entire bill texts from the congress api. It's about 5% complete as of now.",
            "createdAt": "2025-07-17T17:58:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3084949544",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64GCrW",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon amazing! How long has it been running? Just trying to get a sense of when it will be done.",
            "createdAt": "2025-07-18T08:48:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3088591574",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc64JFNX",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab It's be running for about 22 hours and it's 32% complete. Similar to the speed we had for the amendment script.",
            "createdAt": "2025-07-18T12:51:04Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3089388375",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64NUBV",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@MaxMillerLab](https://github.com/MaxMillerLab) It's be running for about 22 hours and it's 32% complete. Similar to the speed we had for the amendment script.\n\nKilling this script because I'm going to use the GovInfo API instead and want to free up resources.",
            "createdAt": "2025-07-18T19:23:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3090497621",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66OU9e",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 8 days (last updated: 2025-07-18)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:17:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3124318046",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66gj-W",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "We currently have the bill text up through congress 114 from my previous script for this issue. It turns out that it didn't get all the way through congress 116 because the queue has a time limit on it. Just going to get the last two congresses of bill text and then figure out how to break it up.",
            "createdAt": "2025-07-28T19:45:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3129098134",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66jebl",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon were we able to break the bill text into clauses prior to creating the embeddings?",
            "createdAt": "2025-07-28T20:54:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3129861861",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66jfzQ",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab The last few bill texts are still downloading. I will look into breaking them down once they are done.",
            "createdAt": "2025-07-28T20:56:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3129867472",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66jhY5",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Ah sorry! I read that as \"we have the embeddings up to 114! While things are downloading, it might be worthwhile to write the script to create the embeddings. I would run the simple model (with no lookahead bias) on the grid.\n\nIt might be worthwhile to create some more complex embeddings models too... this one is supposed to be good: https://huggingface.co/nvidia/NV-Embed-v2\n\nI'm open to others as well if you have ideas!",
            "createdAt": "2025-07-28T20:59:10Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3129873977",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66kCn0",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Gotcha, I think I actually have a script that does embedding, `embed_text.py`. I might have to adjust it for the new text data. Also, I'll use the HuggingFace MCP to check out some new models.",
            "createdAt": "2025-07-28T22:09:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3130010100",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66pJbz",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon awesome! Let me know. For the more advanced embeddings models, it would be good to get a sense of (1) how long it takes to run on an H100 and (2) how large the end data are. That will inform whether a larger model is feasible.",
            "createdAt": "2025-07-29T08:49:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3131348723",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66uLfR",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The bill text download script threw an error while it was running last night. It should be fixed now. So in the meantime, I'll embed some smaller text we already have, probably title or purpose, and see what that is like on the H100.",
            "createdAt": "2025-07-29T13:58:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3132667857",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66wxar",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The titles for each congress have been embedded. They are located at `/export/projects3/mmiller_bill_probability/derived/embeddings/amendment_titles`. Those were done with 'embed_amendment_titles_gpu.py`. They take up about 5GB per congress with the simple embedding model. This was actually from a couple weeks ago, but I never got a chance to really look at the result since we moved onto the neural network.\n\nI'm going to use the same script but modified to embed the description of each bill. I submitted to the HBS gpu queue and it is running right now.\n\n\n",
            "createdAt": "2025-07-29T17:01:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3133347499",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc661w6O",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "When embedding the bill descriptions, it has take about 8 hours to get through half of a congress. However, when looking at the log file, it isn't accessing the gpu on the grid. I'll run it on Lambda tomorrow to see if this problem persists.",
            "createdAt": "2025-07-30T02:18:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3134656142",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc664RRl",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon That is weird! Maybe that model is run on CPU and not GPU? Or it could be something with module settings (eg CPU version of module downloaded)",
            "createdAt": "2025-07-30T08:21:57Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3135312997",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc6686lH",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Found this link: https://huggingface.co/spaces/mteb/leaderboard .Not sure if you've seen it, but it's an current leaderboard of text embedding models. Apparently Gemini 001 is the best available and has a built in 'Semantic_Similarity' metric which could be useful. I'm not sure if it will avoid look-ahead bias though.",
            "createdAt": "2025-07-30T14:09:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3136530759",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66-V5b",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Also, I switched the bill description embedding to the H100 on Lambda and it's working at about 20min per file which is a crazy speed up. Should have results on that in a couple hours.",
            "createdAt": "2025-07-30T15:48:59Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3136904795",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66_rwc",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon man! That is quite a bit faster! This is the smaller model, correct? I also like the model you highlight. Would be good to understand if we can feasibly run it!",
            "createdAt": "2025-07-30T17:35:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3137256476",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66_sLD",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon I think this should be in the other issue right?\n\n> The script to download bill texts has completed running. We now have the text for bills in congresses 108 through 116. Looking a little closer, we have about 20,000 text entries for 15,000 bills in each dataset. This is in line with what I would expect, given that we know there are about 15,000 unique bill_ids in each congress. Also, most bills don't make it very far so they don't get many text versions, but a few get revisions and therefore have new text.\n\n",
            "createdAt": "2025-07-30T17:35:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3137258179",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66_uXe",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Ah, you are right, I'll repost in that issue and delete it here.",
            "createdAt": "2025-07-30T17:38:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3137267166",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66_xMI",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@calebeynon](https://github.com/calebeynon) man! That is quite a bit faster! This is the smaller model, correct? I also like the model you highlight. Would be good to understand if we can feasibly run it!\n\n@MaxMillerLab Yes, this is the smaller model. I can test the Gemini model next!",
            "createdAt": "2025-07-30T17:41:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3137278728",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67Bssc",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The embeddings for bill descriptions are complete are are in the datastore on the Grid and the Dropbox. Total cost: $12.08",
            "createdAt": "2025-07-30T20:52:19Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3137784604",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67KlHK",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon cheap! how big? and maybe we can try Gemini before your meeting with @farnikn?",
            "createdAt": "2025-07-31T14:05:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3140112842",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc67K8ve",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "About 10GB per Congress. Just had the meeting, but I can run that while I wait on some code he's sending.",
            "createdAt": "2025-07-31T14:29:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3140209630",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67LU_m",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab After some further digging, Gemini's embedding model has a couple issues: it's an API so there are rate limits and it maxes out at 10,000 characters of text per embedding. It also allows only one embedding at a time, so it won't benefit from gpu speedup. \n\nI used the HF MCP to find a new model. I'm thinking of using this one instead: https://huggingface.co/BAAI/bge-m3",
            "createdAt": "2025-07-31T14:58:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3140308966",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67MsgO",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'm using the grid gpu to run it right now. It's actually making good progress at about 30 minutes per congress.",
            "createdAt": "2025-07-31T16:49:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3140667406",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67NuxX",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon sounds good! Why do you think that model is a good one for us?",
            "createdAt": "2025-07-31T18:23:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3140938839",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc67OF0m",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab It can handle large amounts of text and is capable of batch processing, this will speed up the embedding. From what I've read, it performs very well for measuring similarity between texts. Its training also included some legal and policy documents. ",
            "createdAt": "2025-07-31T18:58:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3141033254",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67PD4m",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon love it!",
            "createdAt": "2025-07-31T20:45:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3141287462",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc67Pe7r",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Embeddings for BAAI/bge-m3 are done running now and are located at `/export/projects3/mmiller_bill_probability/derived/embeddings/descriptive_text_bge`. Similar in size to the other model, but slightly smaller at about 8GB per Congress. It took about 7 hours on the grid gpu.",
            "createdAt": "2025-07-31T21:32:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3141398251",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67PzCM",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Not bad!",
            "createdAt": "2025-07-31T22:10:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/38#issuecomment-3141480588",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-14T13:23:19Z",
        "labels": [],
        "milestone": null,
        "number": 38,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Bill Probability and Impact"
          }
        ],
        "title": "Text Embeddings",
        "updatedAt": "2025-07-31T22:10:33Z",
        "url": "https://github.com/MaxMillerLab/bills/issues/38"
      },
      {
        "assignees": [
          {
            "id": "U_kgDODNFgeg",
            "login": "calebeynon",
            "name": ""
          }
        ],
        "body": "Step 2. Creating a neural network to output a probability of bill passage using the data pipeline. This probability will be used in creating the exposure measure.",
        "comments": [
          {
            "id": "IC_kwDOMBPlSc6z5URN",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon this is on pause while we figure out the data situation right?",
            "createdAt": "2025-06-30T07:49:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3018146893",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc6z81H-",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yes",
            "createdAt": "2025-06-30T13:01:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3019067902",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63RaUU",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Just talked to @farnikn and I am going to code a simple neural network model that takes my preprocessed data as an input. We will evaluate performance of that model and can make it more complex as necessary.",
            "createdAt": "2025-07-15T18:09:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3074794772",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63f6nh",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon sounds good! Could you please add a \"target completion date\" when you get a chance?",
            "createdAt": "2025-07-16T13:22:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3078597089",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc63hlxK",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "First neural network is running on the grid gpu.",
            "createdAt": "2025-07-16T15:00:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "ROCKET",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3079035978",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63k5L-",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'm currently training on the entire dataset, but it is taking an extremely long time. @MaxMillerLab Do you think it's okay to train on a subset of the data?",
            "createdAt": "2025-07-16T18:55:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3079901950",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63lZZn",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon By \"full data\" do you mean across all congresses? I think the way we should do it is to, say, train on one congress and then test on the next congress. does that make sense? E.g. train on 107th congress and test on 108th.",
            "createdAt": "2025-07-16T19:39:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3080033895",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc63ldP9",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yes, I'm currently training on all congresses. I'll adjust to train on one congress and test on another.\n\nThinking longer term, do we plan on having multiple neural networks? Or will we find a way to narrow to which network is best?",
            "createdAt": "2025-07-16T19:45:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3080049661",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc63m-AH",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "New version of neural net is on the grid. The job is pending because other people's code needs to run first. Not sure how long that will take. I will let you know if it is still pending in a few hours, in which case we may have to use the other gpu's.",
            "createdAt": "2025-07-16T20:34:46Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3080445959",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc630jav",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Still pending behind other people's jobs.",
            "createdAt": "2025-07-17T13:06:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3084007087",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc635y7L",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I wrote a smaller test version of the neural network that uses only 1,000 rows from one pair of congress data sets. This was able to run in the normal short queue in about an hour. Very poor accuracy, but I at least know that the neural network works.",
            "createdAt": "2025-07-17T20:31:28Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3085381323",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64GEkn",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon sounds good! Let's see if we can have something running over the weekend! If it takes too long, we can get a more powerful GPU to use on LambdaLabs!",
            "createdAt": "2025-07-18T08:49:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3088599335",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc64JG-y",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Yeah, it's still pending behind other people's jobs. I'm not sure why it's taking so long to even start running. Is this something to ask RCS?",
            "createdAt": "2025-07-18T12:53:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3089395634",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64Nk-8",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Neural net is training right now. It started at 1:40 and is still on epoch 1/50 \ud83d\ude2c.",
            "createdAt": "2025-07-18T19:54:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3090567100",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64Nwym",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Oh boy... track the progress! If we need to, we can work with some more powerful GPUs next week. This is with 16GB of RAM?",
            "createdAt": "2025-07-18T20:17:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3090615462",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc64OHyu",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yeah, that was with 16GB. I asked Claude if there was a way to speed it up and it said it was a memory management issue. I'm now running a script that should handle that better and I'm running it with 200GB of RAM to be sure.",
            "createdAt": "2025-07-18T21:00:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3090709678",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64l3_j",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I started a Lambda Labs instance with a singular H100 GPU at $3.29/hr. I'm going to start by just training on two congresses worth of data. The only way I've found to access data in Lambda Labs is first to transfer it to the Dropbox. So when we're ready to train on all the data, I'll sync the Dropbox and Grid folders. ",
            "createdAt": "2025-07-21T14:07:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3096936419",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64nKHA",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab After some debugging, the neural network is now running on Lambda Labs. I installed the 'Guest Agent' so you should be able to monitor GPU and CPU usage from your account online.\n\nI'll create the documentation for set up now.",
            "createdAt": "2025-07-21T15:35:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3097272768",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64qWMD",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I got a weird result where the training is using 100% of CPU but almost 0% of the GPU capabilities. I was pretty sure that it had to do with data loading and handling, so I've spent the day trying to figure out why this is happening. I've gotten to the point where it is utilizing like 5% of the GPU, but still taking a significantly long time (7 days for training). I'm thinking that it just has to do with reading that much data into the model continuously, so I'm just going to try to read it all into RAM at the start and see if that helps. I was hesitant to do this before because when we include all of the data, it will be probably around 200G. But with just a pair it should be okay right now.\n\nWorst case scenario, I'll shut down the GPU session later and we can discuss potential solutions tomorrow.\n ",
            "createdAt": "2025-07-21T19:28:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3098108675",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc64uD01",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "**I got it to train!!!** The solution ended up being to simply read the entire dataset into RAM instead of chunking it. I trained on just Congress 108 today, and the H100 was able to get that done in less than 10 minutes. I was correct that the main slowdown was reading the data continuously. \n\nWhen training it got to 99.9% accuracy which is suspicious. But then I validated this model on Congress 109 data (which it had never seen before) and it still was at 99.1% accuracy. And there was no class bias too, which was my first main thought.\n\nI'm still very suspicious of these results especially since this was a first attempt at the neural net. Either I'm really lucky or there is something helping the model that shouldn't be.\n\nI'm going to shut down the GPU for today and get to work verifying these results. After verification we can start training on all of the Congress data. Sorry for the spam in this thread today lol.\n\n",
            "createdAt": "2025-07-21T21:20:23Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3099082037",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc643xct",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon man that is awesome!! And you kept it under $25!!\n\nI agree... that is suspicious... how do you define \"success\" here? And presumably the neural net gives a continuous number [0,1] whereas the outcome variable is {0,1}. This is training on one Congress and testing on the next, right?\n\nIf you could write up a short one-pager (really, less is more here) on the important decisions here, it would be helpful. We can then organize with Farnik. In the meanwhile, since the H100 gets it done in 10 min, we should expand the script to run all congresses in a loop... should mean like 2h of running.\n\nOverall, this is awesome!! Sounds like we can basically train the model for $7, which is a huge win for so much data.\n\nQuick other question: what are you doing with the data afterward? Is it in an S3 bucket (we're charged for that, which is why I'm asking). Thanks a ton!!!",
            "createdAt": "2025-07-22T08:26:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3101628205",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc647pYE",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I used the default for neural network classification which I believe rounds up starting at 0.5, otherwise it rounds down. So anything greater that 0.5 is mapped to 1 and less than 0.5 mapped to 0. This is training on one congress (108) and testing on the next (109).\n\nYes, I can do both of these things. The data is in our Dropbox folder (so are the scripts) because it integrates nicely with Lambda Labs.",
            "createdAt": "2025-07-22T13:07:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3102643716",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc648ljD",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Got it! Can you plot a histogram of our continuous measure so I get a sense of how it looks? This would only make sense if probability of passage is super predictable at proposal, which seems weird. Does the probability change over time within a bill at all?",
            "createdAt": "2025-07-22T14:03:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3102890179",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc648yKG",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab So you want to see the actual continuous output of the neural network? Yes, I can create that and then get back to you about the probability change.",
            "createdAt": "2025-07-22T14:15:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3102941830",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc6481sw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Yep! In a histogram! It will give me a sense of what is going on. You can post the picture in the response here",
            "createdAt": "2025-07-22T14:19:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3102956336",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65B68q",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "<img width=\"730\" height=\"567\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c2af6bea-5451-4cba-af51-e67348536219\" />",
            "createdAt": "2025-07-22T18:39:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3104288554",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65B87L",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yeah so it looks like the model is predicting very much at the extremes. I don't think this will be very conducive to our plan to track changes in probability because it won't actually change that much.",
            "createdAt": "2025-07-22T18:42:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3104296651",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65Czp1",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "**Main Decisions to Make**\n1. How do we adjust the model to be *less* confident? While it's accurate right now, it doesn't provide much information on changing probabilities.\n - A possibility here is to maybe think in binary terms instead of continuous. We could just check to see how many bills convert from 0 -> 1 or vice versa and analyze stock trends following a shift from 0 to 1. I'm not sure how significant this would be.\n\n2. Which Congress datasets do we use for training, which ones do we use for validation?\n\n3. Do we want to add text embedding into the data?",
            "createdAt": "2025-07-22T19:24:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3104520821",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65FApU",
            "author": {
              "login": "farnikn"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@calebeynon -- Awesome that you got the network running, and the workflow you\u2019ve set up is really impressive! Now is probably a good time to adjust a few details in the model. For the issue of model being overly confident in its predictions, a few common causes I can think of are these:\n\n1/The final layer in your network may not be using the right activation function. It\u2019s good to double-check that -- for binary classification, a `sigmoid` activation is typically used (to output the probability of class 1); if you have two output units and want a full probability distribution over two classes, `softmax` is better.\n\n2/ Make sure the loss function matches the output activation -- use `binary_crossentropy` if your final layer is `sigmoid`, and `categorical_crossentropy` if you\u2019re using `softmax`; we can also chat more about why these loss functions work the way they do and how they\u2019re mathematically related.\n\nAnother important point that you correctly brought up in our last call is that our dataset is imbalanced (many more fail cases than pass). In such cases, a neural network can \u201ccheat\u201d by always predicting the majority class, since that minimizes the loss superficially. One effective way to deal with this is by using class weights during training. This tells the model to care more about the minority class by penalizing mistakes on it more heavily.\n\nThe last think I can think of at the moment is the metrics we want to use. `Accuracy` alone can be misleading when the data is imbalanced. It would be nice to also look at AUC-ROC or precision to get a better sense of how well the model handles both classes.",
            "createdAt": "2025-07-22T23:22:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3105098324",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65Fayc",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@farnikn Thank you for the adjustments! The version I reference above used BCE with a sigmoid activation function in the output layer. I will train another model with categorical crossentropy and the softmax function and report back.\n\nYeah, I thought for sure we would get class bias in this model but the precision very closely mirrors the accuracy. Additionally, I looked at the distribution of predictions and it very closely matches the distribution of the actual outcomes. Do you think we still need to add class weights? ",
            "createdAt": "2025-07-23T00:10:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3105205404",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65Fnpg",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Just a heads up I'm running the neural net on Lambda Labs again. Should be less than an hour for sure.",
            "createdAt": "2025-07-23T00:44:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3105258080",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65J5NI",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon sounds good. What data are we using for prediction here? I just can't believe that whether a bill will pass or not is this predictable... do we have an example of the probability of passage moving a lot within a bill? Can we understand why that happened. I'm worried that we have some leakage here (but then I don't understand why the data trained on the 108th congress does so well on the 110th congress!). \n\nOn the other hand... maybe bills just are this predictable! @calebeynon could you pick your favorite deep research engine and look at the literature that tries to estimate this and see if they find something similar? If this is the case, we can't be the first ones to discover it.",
            "createdAt": "2025-07-23T08:02:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3106378568",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65LGNd",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Hi @calebeynon @ceynon \u2014 Here is a collected list of research links on whether US congressional bill passage is predictable, as discussed. These include major machine learning, neural net, and political science analyses, as well as arguments on both sides:\n\n- Predicting Bill Passage (Stanford CS229, 2015, PDF): Machine learning analysis of congressional bill passage with discussion of predictability and outcomes: https://cs229.stanford.edu/proj2015/242_report.pdf\n- The Keys to Legislative Success in the U.S. House of Representatives (JSTOR): https://www.jstor.org/stable/3598611\n- Predicting and understanding law-making with word embedding-based machine learning (PMC): Uses ML to forecast bill passage, discusses model performance limits and inherent unpredictability: https://pmc.ncbi.nlm.nih.gov/articles/PMC5425031/\n- Artificial Intelligence can predict which congressional bills will pass (Science): ML analysis and accuracy discussion: https://www.science.org/content/article/artificial-intelligence-can-predict-which-congressional-bills-will-pass\n- Predicting Congressional Bill Outcomes (Stanford CS229, 2012, PDF): https://cs229.stanford.edu/proj2015/014_report.pdf\n- Can U.S. congressional legislative activities be predicted? (Blog): Review of data-driven prediction efforts and process bottlenecks: https://kennethxintao.com/2023/08/01/can-congressional-legislative-process-be-predicted/\n- A Deep Learning Model to Predict Congressional Roll Call Votes (SSRN): NN model with ~67% accuracy on roll call votes: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3778602\n- Predicting the Passage of Bill Using Machine Learning (Romanpub): High-accuracy neural net prediction (albeit for Korea): https://romanpub.com/resources/13.%20Predicting%20the%20Passge%20of%20Bill%20Using%20Machine%20Learning%20Big%20Data.pdf\n- Textual Predictors of Bill Survival in Congressional Committees (PDF): https://aclanthology.org/N12-1097.pdf\n- Introduction to the Legislative Process in the U.S. Congress (CRS): Official perspective, process variability: https://www.congress.gov/crs-product/R42843\n\nLet me know if you'd like the blurbs/takeaways for each, or if you need a focused summary!",
            "createdAt": "2025-07-23T09:24:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3106693981",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65Qu9a",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@calebeynon](https://github.com/calebeynon) sounds good. What data are we using for prediction here? I just can't believe that whether a bill will pass or not is this predictable... do we have an example of the probability of passage moving a lot within a bill?\n\nI can probably find one. I doubt that all of the bills have either a 0 or 1 for the entirety of their life in the dataset.",
            "createdAt": "2025-07-23T13:05:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3108171610",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65SnUN",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon thanks! Also, check out \"perplexity comet\". It's their new agentic web browser. I'm having a lot of fun with it (you may have guessed it did the lit review comment)",
            "createdAt": "2025-07-23T13:48:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3108664589",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65S1MT",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "It sound's like a few of those articles got up to a similar precision/accuracy as our neural network. The first one got 99%+ on some of their models, the third one got 96% precision and the fifth one got 94%.",
            "createdAt": "2025-07-23T13:53:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3108721427",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65Tf9a",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon wow!! Who knew! We are just using actions and co-sponsors, right?",
            "createdAt": "2025-07-23T14:27:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3108896602",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65TqWT",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab We also use committee information and bill status.",
            "createdAt": "2025-07-23T14:38:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3108939155",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65U5RW",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon Got it!! My guess is we can find some changes from looking at changes in bill status and co-sponsors",
            "createdAt": "2025-07-23T16:07:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3109262422",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65Vq5X",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Gotcha, I found some examples of bills with near complete reversals in probability. I'm trying to figure out what is changing now: \n\nhr1973-109: 0.000 \u2192 0.988 (change: +0.988, n=495)\nhr972-109: 0.013 \u2192 0.991 (change: +0.978, n=615)\nhr1953-109: 0.000 \u2192 0.895 (change: +0.895, n=459)\nhconres90-109: 0.149 \u2192 0.999 (change: +0.850, n=555)\nhr22-109: 0.000 \u2192 0.832 (change: +0.832, n=673)\nsres42-109: 0.002 \u2192 0.772 (change: +0.769, n=617)",
            "createdAt": "2025-07-23T17:12:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3109465687",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65XfcC",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "<img width=\"1300\" height=\"846\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e483f2c6-636e-4bf2-88c5-38c1864654b2\" />\n\nThis is an example of one of those bills' probability over time. Now I'll look specifically what is happening on the days of large change to see if there is a clear factor.",
            "createdAt": "2025-07-23T19:54:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3109943042",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65loct",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon interesting! I told you my logic on this earlier. Most bills live in either \"passed\" or \"won't pass\" for most of their lives. I don't like that the bill above is at 0 though... Did this one's passage probability jump when it was proposed? I'm talking about hr22 in 109.",
            "createdAt": "2025-07-24T14:16:19Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3113649965",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65oCUA",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab So I looked at the changes in the bill for the day it jumped. Basically it looks like it moved onto the Senate calendar.\n\n<img width=\"444\" height=\"81\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f30dba24-6a34-4903-bf64-339a0103ba7f\" />",
            "createdAt": "2025-07-24T17:30:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114280192",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65oV9O",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Here's the bins graph you asked for. Definitely not at the 45 degree target.\n\n<img width=\"1466\" height=\"721\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f1aa80a8-4a9e-4ff7-b5cc-941e04d65c8a\" />",
            "createdAt": "2025-07-24T18:00:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114360654",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65oYs8",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon got it! But this is super useful! So this means that the model isn't actually all that accurate! Which is ok... it's just a first pass!\n\n@farnikn do you have some suggestions for how we might deal with this? I was a little suspicious when we got such high accuracy, but now I see it's mostly spurious!",
            "createdAt": "2025-07-24T18:04:23Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114371900",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65oZQa",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon One suggestion... for each bill get rid of all rows with dates before the bill is proposed and after it is passed. That might help us.",
            "createdAt": "2025-07-24T18:05:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114374170",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65ocZF",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon what would this look like if we dropped duplicate observations within each bin? I mean dropping duplicates by bill-estimated probability",
            "createdAt": "2025-07-24T18:10:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114387013",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65ohaS",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Looks very similar, but note the change in the y-axis now going up to only 50%. This would imply we are getting some class bias and the neural net is over-predicting fail. \n\n<img width=\"1470\" height=\"711\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8b993c17-f831-48b4-a22f-5bbdee22bd1b\" />",
            "createdAt": "2025-07-24T18:17:13Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114407570",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65ojCI",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon yes, that's definitely it! It gets an excellent score by getting the failures right. Why are there so many failure observations? Just many bills sit around in committee or die in committee?",
            "createdAt": "2025-07-24T18:19:46Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114414216",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65olZX",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab From the internet and some searching, most bills don't get out of committee and thus die there. I can check our data specifically if you would like confirmation of that.",
            "createdAt": "2025-07-24T18:23:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114423895",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65oxbw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon no I believe it! I guess we need to change the model a bit! @farnikn any suggestions would be much appreciated",
            "createdAt": "2025-07-24T18:40:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114473200",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65oylF",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon in the meanwhile, could you adapt your exposure script to work with the real output? That way we can have a first pass at the exposure measures (even if we know the model is bad).",
            "createdAt": "2025-07-24T18:41:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114477893",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65o0Ky",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Yes, I'll create a separate issue for that.",
            "createdAt": "2025-07-24T18:43:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3114484402",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65-BOH",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Do you want me to create a neural network script that processes all of the congress data? Or should I wait on adjustments from @farnikn before building it?",
            "createdAt": "2025-07-25T19:13:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3120042887",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc65-EPM",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon build the script and test it out. I'd like to see that plot with all the congresses (even though I don't really think it will be better). It's not that expensive, so it's worthwhile to have it ready and tested.",
            "createdAt": "2025-07-25T19:18:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3120055244",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc65-qXw",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Sounds good. Currently compressing the necessary csv's to hdf5 files using a slightly modified version of how I did it for 108 and 109. Should take a couple hours.",
            "createdAt": "2025-07-25T20:13:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3120211440",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66Rzbz",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "The script to compress the csv's was successful. I also wrote a script to train on the first 6 congresses and test on the next 2. I will run this on Lambda next (in the morning).",
            "createdAt": "2025-07-28T03:24:32Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3125229299",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66VvKE",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon sounds like a plan!!",
            "createdAt": "2025-07-28T09:03:23Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3126260356",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc66ZX2I",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Data is synced into lambda and the neural net is training!",
            "createdAt": "2025-07-28T13:19:38Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3127213448",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66aBHX",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "training and validation complete. compiling metrics and graphs now.",
            "createdAt": "2025-07-28T14:01:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3127382487",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66d2KD",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Here's what it looks like when it's trained on congress 108-114. So the problem gets worse when we train on more data.\n\n<img width=\"1464\" height=\"718\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/083b6680-9dba-411d-8dc4-d87551529a50\" />",
            "createdAt": "2025-07-28T18:00:46Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3128386179",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc66eKfx",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon this sounds right. The problem is that our data are not stationary, so a longer training window hurts us rather than helps us. I had this suspicion, but I am glad you confirmed!",
            "createdAt": "2025-07-28T18:29:41Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3128469489",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMBPlSc67P9__",
            "author": {
              "login": "calebeynon"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "After meeting with @farnikn, he recommended using class weights to penalize the network more for misclassifying the passed bills as fails. This should incentivize the network to classify more towards pass during training. If this doesn't work we'll try to adjust the architecture of the network. \n\nI created a new version with class weights and the attached image is the resulting graph. So it's still not good, but I think it's because I tried too aggressive of a strategy to start out with. You can see that the true percentage of passes maxes out at 5% even for the 95%-100% bin. My impression is that the network now went too far in the opposite direction and is overclassifying passes. Going to try a different class weights version that is less aggressive on the penalization.\n\n<img width=\"1467\" height=\"715\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/edfcc282-b67b-4221-a17f-36358ce50bb1\" />",
            "createdAt": "2025-07-31T22:24:28Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3141525503",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMBPlSc67bP6Y",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@calebeynon ugh awful haha! Let's hope we can improve it! I think it would help us if we could eliminate rows of bills after they are no longer being considered. This would involve finding when bills explicitly fail in committee. It would allow us to reduce the number of 0 rows substantially.",
            "createdAt": "2025-08-01T12:51:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/bills/issues/24#issuecomment-3144482456",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-06-17T14:33:31Z",
        "labels": [],
        "milestone": null,
        "number": 24,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Bill Probability and Impact"
          }
        ],
        "title": "Coding the NN",
        "updatedAt": "2025-08-01T12:51:43Z",
        "url": "https://github.com/MaxMillerLab/bills/issues/24"
      }
    ],
    "MaxMillerLab/health": [
      {
        "assignees": [
          {
            "id": "U_kgDOCffcXA",
            "login": "siyusun1108",
            "name": ""
          }
        ],
        "body": "- [ ] Extract Medicare age coefficients from \"02 create medicare benefits code\"\n- [ ] Create function to calculate Medicare benefits by age (conditional on receipt)\n- [ ] Implement forward projection: calculate Medicare benefits \"h years ahead\" for each person\n- [ ] Integrate Medicare benefits calculation into simulation loop\n- [ ] Add proper discounting for future benefits (cumulative inflation, wage growth, survival probabilities)",
        "comments": [],
        "createdAt": "2025-07-29T04:39:13Z",
        "labels": [],
        "milestone": null,
        "number": 30,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Health"
          }
        ],
        "title": "Integrate Medicare benefits calculation into the simulation to compute expected Medicare benefits for each individual over their lifetime",
        "updatedAt": "2025-07-29T04:39:13Z",
        "url": "https://github.com/MaxMillerLab/health/issues/30"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOCffcXA",
            "login": "siyusun1108",
            "name": ""
          }
        ],
        "body": "- [x] Create a new `medicaid/` module (similar to `medicare/` and `ss/`)\n- [x] Write a function to compute Medicaid receipt probability using regression coefficients\n- [x] Bring that logic into the simulation \u2014 will need to read how existing programs are integrated\n- [ ] Decide whether to simulate receipt (binary) or just attach probability\n- [ ] Locate in the simulation script where simulated are generated (can be across cohort, age, and year), so we can explore different policy options\n\n",
        "comments": [
          {
            "id": "IC_kwDOLsa75c63f7nQ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 Could you please add a \"target completion date\" when you get a chance? This looks great otherwise!",
            "createdAt": "2025-07-16T13:23:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3078601168",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c63gBoS",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 we should have our own project space on the HBS grid now. You can request GPU access through [this link](https://forms.office.com/pages/responsepage.aspx?id=Tlb9CUK_IUOPLbjkgvhjXMoIB6PHisBIlawtyGb7ibhUNTJJOERNR1pNRzUzS0g4WkZKWjNHVjBTSy4u). We can chat about how to actually set aside the resources you need a little later (I have a script that does this, so it will be super easy).",
            "createdAt": "2025-07-16T13:28:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3078625810",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c63lIzS",
            "author": {
              "login": "siyusun1108"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Thanks, Max! I\u2019ve already assigned a completion date for this issue \u2014 will aim to stay on track and adjust if needed.\n\nAlso, I\u2019ve signed up and got access to the GPU grid space. I spent some time exploring it and located our project folder yesterday \u2014 just wanted to make sure I understand the layout before diving in. Looking forward to seeing the script!\n",
            "createdAt": "2025-07-16T19:15:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3079965906",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c63laSH",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 I should be able to add it to the repo on Friday!",
            "createdAt": "2025-07-16T19:40:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3080037511",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c65gQci",
            "author": {
              "login": "siyusun1108"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab A small update: finished learning the simulation code, will start working on bringing in the medicaid coefficients into the simulation tomorrow. ",
            "createdAt": "2025-07-24T06:43:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3112240930",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c65lvBC",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 thanks for the update! Let me know if I can help. Are you able to use the hbsgrid utility scripts I added?",
            "createdAt": "2025-07-24T14:23:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3113676866",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c65xnaF",
            "author": {
              "login": "siyusun1108"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Thanks! I quietly tested the GPU access on the grid and confirmed that it's working. I plan to use it more seriously when I integrate the Medicaid probability into the simulation.",
            "createdAt": "2025-07-25T07:54:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3116791429",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c656FHZ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 great! Thanks for the update!",
            "createdAt": "2025-07-25T16:04:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3119010265",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66OZfy",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@siyusun1108 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue is 2 days overdue (target date was: 2025-07-25)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:48:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/28#issuecomment-3124336626",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-16T07:32:25Z",
        "labels": [],
        "milestone": null,
        "number": 28,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Health"
          }
        ],
        "title": "Implement Medicaid receipt regression into simulation",
        "updatedAt": "2025-07-28T06:10:57Z",
        "url": "https://github.com/MaxMillerLab/health/issues/28"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjI2OTA0NTcx",
            "login": "zahrahnabdul",
            "name": ""
          }
        ],
        "body": "Max & I to discuss week of 7/28\n\nMy current understanding of the task (could be inaccurate):\n1. Define terminal ratios: pick target Medicare-to-GDP and Medicaid-to-GDP shares for year 100\n2. Assume persistence of the gap: state assumption that any spread between spending and revenue shares remains constant into the infinite future\n3. Project both series forward: grow each at long-run real GDP growth (or alternate scenario) beyond year 100\n4. Discount to present: use agreed real discount rate (Natasha suggested \u22482%) to compute the present value of the infinite tail for each program\n5. Add PV of current-cohort shortfall: use age-decile PVs for everyone 15+ alive today to capture obligations over the first 100 years\n6. Combine pieces: sum current-cohort PV + terminal tail PV to obtain total unfunded obligation\n",
        "comments": [
          {
            "id": "IC_kwDOLsa75c63dinN",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul this looks correct. We can meet up and discuss after making some progress. One thing: I think this can be split into two different issues: \n1. The terminal value calculations (after 100 years);\n2. The intermediate calculations (within first 100 years)\n\nThese will require different methods and different data, so I think we can split them up.",
            "createdAt": "2025-07-16T10:37:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/26#issuecomment-3077974477",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66OZfj",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 11 days (last updated: 2025-07-16)\n- No start date\n- No target completion date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:48:57Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/26#issuecomment-3124336611",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-15T17:32:06Z",
        "labels": [],
        "milestone": null,
        "number": 26,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Health"
          }
        ],
        "title": "Total-obligation exercise outside the simulation",
        "updatedAt": "2025-07-27T11:48:57Z",
        "url": "https://github.com/MaxMillerLab/health/issues/26"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjI2OTA0NTcx",
            "login": "zahrahnabdul",
            "name": ""
          }
        ],
        "body": "Gather Medicare expenses and revenue projections and age distribution data from 1995 to 1989",
        "comments": [
          {
            "id": "IC_kwDOLsa75c63djTf",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul great! Note that I've added these to the \"Health\" project. On the right side, you can select a \"target completion data\" for this issue. Would you mind doing that?",
            "createdAt": "2025-07-16T10:38:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3077977311",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c6438fP",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul how is this coming along? any progress? remember to comment on issues you are working on at least once every 5 days. even if it is just to say why there has not been progress.",
            "createdAt": "2025-07-22T08:38:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3101673423",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c65aI7M",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi\u202f@MaxMillerLab! I didn\u2019t receive my work laptop until last night so I just set up my project folders today. Here\u2019s what I\u2019ve done so far: \n\n- Trustee reports: added the 1989\u202f\u2013\u202f1995 Medicare Trustee Report PDFs to datastore/raw/healthcare/medicare/trustee_reports/. \n- MEPS pre\u20111996: According to the MEPS FAQ, the only pre\u20111996 source is the 1993 NEHIS survey, which isn\u2019t directly comparable to MEPS\u2011IC. I\u2019m investigating whether it\u2019s usable/if there are any alternatives. \n\nI\u2019ll post a more detailed status update tomorrow after a bit more digging. \n\nThanks for your patience. Let me know if you\u2019d like me to shift my priorities.",
            "createdAt": "2025-07-23T22:21:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3110637260",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c65lpdD",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul fantastic! I appreciate the update. Any sense of whether we can find updated age distribution projections in these?",
            "createdAt": "2025-07-24T14:17:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3113654083",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c65p8_U",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I've been able to find a table similar to the one attached for almost every year prior to 1996 (I'm still searching for 1989 and 1990).\n\nHowever, after looking through the clean_age_distribution data file and the Slack conversations you've had with Justin, I'm not sure these have the needed granularity. There are only three age groups (under 20, 20-64, 65+) and the estimates are done in five-year intervals.\n\nI'm sharing this here to get your thoughts, but my sense is that I'll need to keep looking. Is that correct?\n\n<img width=\"362\" height=\"391\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bdf494c1-ff50-4dc3-b3a8-c71bd68c1dd7\" />",
            "createdAt": "2025-07-24T20:11:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3114782676",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c655o_b",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul that is actually still helpful! In have an idea of how we can use that to fill in. Especially given the existing info we have. Can you gather these?",
            "createdAt": "2025-07-25T15:53:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3118895067",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c655pWL",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab, another update:\n\nI still haven't been able to find the age distribution data at the level of granularity we need. After chatting with Justin, it seems like contacting SSA again and possibly submitting a FOIA request might be the most promising options. I'm going to email them and get the ball rolling on FOIA this afternoon.\n\nI was able to get the expenditure projections from the trustee reports for 1989 to 1995, though. I'm reading through the project documentation to see what the best way to add it is.",
            "createdAt": "2025-07-25T15:53:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3118896523",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c655q7P",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@zahrahnabdul](https://github.com/zahrahnabdul) that is actually still helpful! In have an idea of how we can use that to fill in. Especially given the existing info we have. Can you gather these?\n\n@MaxMillerLab will do! ",
            "createdAt": "2025-07-25T15:54:14Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3118902991",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c656C80",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul sounds like there are three things we have going on now:\n1. Integrate expenditure projections\n2. File FOIA\n3. Gather coarse age projections\n\nI like this plan! We can chat about how we can turn (3) into more granular age projections next week.",
            "createdAt": "2025-07-25T16:03:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3119001396",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c656x6I",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Sounds good! I just submitted a FOIA request with the FOIA SSA liaison and emailed the SSA Office of the Chief Actuary directly. I'm working on gathering the coarse age projections for 1989 to 1999 now and will send an update when I finish.",
            "createdAt": "2025-07-25T16:25:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3119193736",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c659mQc",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Just finished gathering the coarse age projections for 1989 to 1999. I have to finish something else for Natasha this afternoon, but I'll send another update when I'm able to make progress on integrating the expenditure projections next week.",
            "createdAt": "2025-07-25T18:34:30Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3119932444",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66OZfc",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue is 2 days overdue (target date was: 2025-07-25)\n- No start date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:48:56Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3124336604",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66cjnF",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab \n\nUpdate: based on how things are used in the code, it seems like the best places to add the 1989-1995 expense and revenue projection data are in these files:\n- 'high_cost_scrapped_from_graph_1996_2015.xlsx'\n- 'income_rate_scrapped_from_graph_1996_2011.xlsx'\n- 'intermediate_cost_scrapped_from_graph_1996_2011.xlsx'\n- 'Medicare_Expenses_as_percentage_GDP.xlsx' (used in 04_create_medicare_expense_projections.py; goes back to 1996)\n\nIt seems like the \"scraped from graph\" files are fed into 01_create_funding_projections.py to provide income and cost rate data for 1996 to 2011/2015 (different files have the data for 2012/2016 to 2024).\n\nJustin is going to share the Excel function he used to scrape the data from the graphs. After I have that, I'll be able to make the new additions.",
            "createdAt": "2025-07-28T16:29:19Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3128048069",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66pIHx",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul that sounds like a plan! I think we have two options:\n1. Add the new data to these files keeping the formatting exactly the same; or\n2. Add the new data as new files. This option is best if formatting cannot be kept identical;\n\nIf option 1 is doable, then we can just extend the years in `01_create_funding_projections.py` and `04_create_medicare_expense_projections.py` to process those data. If it isn't, then we will need to add some new code. Let me know which you think is doable.",
            "createdAt": "2025-07-29T08:48:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3131343345",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c668i9O",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab I think option 1 is doable. The formatting for the data from the earlier years should be identical after I scrape the data from the graphs. \n\nJustin shared the approach he used to scrape the data from the trustee reports yesterday evening. I'll be able to try this approach this afternoon and will report back after I finish.",
            "createdAt": "2025-07-30T13:47:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3136433998",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c67D96f",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Hi @MaxMillerLab, I just finished scraping and adding the 1989-1995 expense and revenue projection data to these files (I'll update the file names to reflect data availability beginning in 1989 when I update the code file that reads these in):\n- 'high_cost_scrapped_from_graph_1996_2015.xlsx'\n- 'income_rate_scrapped_from_graph_1996_2011.xlsx'\n- 'intermediate_cost_scrapped_from_graph_1996_2011.xlsx'\n\nIt seems like the trustee reports didn't include Medicare expenses as a percentage of GDP prior to 1994, but they did include disbursements. I'm going to see if I can find something for each of the missing years (1993-1989) from SSA's Office of the Chief Actuary with their US GDP projections so that I can use the disbursement data to calculate the percentages.",
            "createdAt": "2025-07-31T02:40:16Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3138379423",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c67KsXF",
            "author": {
              "login": "zahrahnabdul"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Another update: after some digging, I found that the Medicare expenses as a percentage of GDP were in the OASDI trustee reports instead of the HI trustee reports prior to 1994. I'm currently scraping the data for these years and will report back when finished.",
            "createdAt": "2025-07-31T14:12:54Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3140142533",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c67Kugs",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zahrahnabdul thank you! Also, if you could, please add some documentation on Justin's approach for scraping the figures. The goal is for future us to be able to replicate it based on your documentation.",
            "createdAt": "2025-07-31T14:14:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/25#issuecomment-3140151340",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-15T17:22:22Z",
        "labels": [],
        "milestone": null,
        "number": 25,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Health"
          }
        ],
        "title": "Collect long-run demographic & health-spending data",
        "updatedAt": "2025-07-31T14:14:51Z",
        "url": "https://github.com/MaxMillerLab/health/issues/25"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjMyOTg1MDM3",
            "login": "zihuahe",
            "name": "Zihua He"
          }
        ],
        "body": "by age group\n2000-2024\n\ngo back further to 1980/9\n\n2025-2100\n\n2000-2075\n\n1989+75\n\nregion? US only\n\nsource? social security administration, potential UN, WB\ncopy raw data to another location\nhttps://www.dropbox.com/home/Zihua%20He/Health/Empirics/data/raw/healthcare/price_index/orig\n\noutcome\ndata\n\ndeadline\ntwo weeks",
        "comments": [
          {
            "id": "IC_kwDOLsa75c6435BL",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zihuahe any update on this? remember to comment on issued you're working on at least every 5 days. Also, if you have made progress, please detail it on here.",
            "createdAt": "2025-07-22T08:34:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3101659211",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66Qmzg",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Working on this issue and expecting to commit my code by tomorrow evening ",
            "createdAt": "2025-07-28T01:24:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3124915424",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66Qomk",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I received such an error when I'm accessing Health folder in DropBox (https://www.dropbox.com/home/Zihua%20He/Health)\n\nYou aren't a member of this team. Please reach out to [your admin](https://www.dropbox.com/help/9119?path=dropbox_for_business) for help.\n\nProfessor Miller @MaxMillerLab, can you please advise?",
            "createdAt": "2025-07-28T01:30:05Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3124922788",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66Vs-Y",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zihuahe what is the associated email for your account? I probably just need to share it wit you.",
            "createdAt": "2025-07-28T09:00:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3126251416",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66VuOV",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zihuahe great on committing your code soon, but it would be nice to understand what sources your using and where you found the data. For this issue, data is much more important than code.",
            "createdAt": "2025-07-28T09:02:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3126256533",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66l5Pv",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@zihuahe](https://github.com/zihuahe) what is the associated email for your account? I probably just need to share it wit you.\n\n@MaxMillerLab zihuahe@hsph.harvard.edu",
            "createdAt": "2025-07-29T03:22:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3130495983",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66l5tY",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@zihuahe](https://github.com/zihuahe) great on committing your code soon, but it would be nice to understand what sources your using and where you found the data. For this issue, data is much more important than code.\n\n@MaxMillerLab I'm no longer able to access the data set in the Dropbox folder, so I need to wait for it to be accessible again.",
            "createdAt": "2025-07-29T03:23:27Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3130497880",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c66pCzS",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zihuahe I'm sorry to hear that! Were you able to access it before?",
            "createdAt": "2025-07-29T08:42:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3131321554",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c66177K",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@zihuahe](https://github.com/zihuahe) I'm sorry to hear that! Were you able to access it before?\n\n@MaxMillerLab Only once after the meeting I had with you last time.\n\nI'm in contact with HUIT (ithelp@harvard.edu) to resolve the issue\nTicket number for the issue is INC05973018 - Re: REQST0156722\n\nIn the meantime, can you please share the dataset with me via email so I can test out?",
            "createdAt": "2025-07-30T02:55:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3134701258",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsa75c667OTQ",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@zihuahe I don't think there is a dataset for me to share! The goal is for you to find some sources that will help us extend our data backwards. Which data are you referring to?",
            "createdAt": "2025-07-30T12:28:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3136087248",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsa75c67EHri",
            "author": {
              "login": "zihuahe"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@zihuahe](https://github.com/zihuahe) I don't think there is a dataset for me to share! The goal is for you to find some sources that will help us extend our data backwards. Which data are you referring to?\n\n@MaxMillerLab \n\nAccording to the reply from HUIT as shown below, it could have been a system restriction related to academic enrollment. I'll reach out to Registrar's office for a resolution. In the meantime, I can work with external data from internet instead.\n\nHi Zihua,\n \nThank you for getting back to me, I found out the issue on your account. It looks like you currently have a FERPA block on your account, this would break Dropbox SSO. If you need to get into your Dropbox account you would need to reach out to the Registrar's office and ask to have it removed.\n \nThank you!\n-Greg\n\n\n--\nGreg Golden\nHarvard University Information Technology\nHUIT Service Desk Phone (617) 495-7777\n[IT Help - Get answers anytime!](https://harvard.service-now.com/ithelp)",
            "createdAt": "2025-07-31T03:11:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/health/issues/24#issuecomment-3138419426",
            "viewerDidAuthor": false
          }
        ],
        "createdAt": "2025-07-15T14:19:20Z",
        "labels": [],
        "milestone": null,
        "number": 24,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Health"
          }
        ],
        "title": "Population projection",
        "updatedAt": "2025-07-31T03:11:33Z",
        "url": "https://github.com/MaxMillerLab/health/issues/24"
      }
    ],
    "MaxMillerLab/foreign_influence": [
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjM3ODQ4MTMy",
            "login": "MaxMillerLab",
            "name": "Max Miller"
          }
        ],
        "body": "@MaxMillerLab  can you please check whether tariffs are related in the cross-sedction with meetings?  We would like to extend the unidentified results in Section 2.5 \\subsection{Motivating evidence} to tariffs.",
        "comments": [
          {
            "id": "IC_kwDOLsBrFs63MtT3",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MarcoGrotteria sure thing! I'm on it!",
            "createdAt": "2025-07-15T13:16:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3073561847",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs6435j2",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MarcoGrotteria I haven't been able to make much progress on this while on vacation. I will aim to make progress next week.",
            "createdAt": "2025-07-22T08:35:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3101661430",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs66YcSa",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MarcoGrotteria checked this out today.\n\n**Results**:\n1. Similar cross-sectional regression do NOT \"work\" for tariffs. What I mean is that in the cross-section countries that meet do not have significantly higher numbers of aligned actions;\n2. Unidentified local projections work very well for cumulative aligned actions;\n3. Unidentified local projections do NOT work very well for trade-weighted tariff rate.\n\n**What do do?**\nI think we have a couple of options:\n1. Report both and talk about how selection might be different (e.g. larger countries tend to lobby more and get more foreign aid, but there are not necessarily more tariff bills about those countries);\n2. Report only the tariff unidentified results;\n3. Report only identified results.\n\nWe can chat about best course of action tomorrow.",
            "createdAt": "2025-07-28T12:18:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3126969498",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs66Ye80",
            "author": {
              "login": "MarcoGrotteria"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I would say option n.1 . There is no reason why selection has to be the same and I guess tariff are rarer and even affect multiple countries at the same time. So maybe it\u2019s not crazy",
            "createdAt": "2025-07-28T12:21:06Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3126980404",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsBrFs66YhUI",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MarcoGrotteria I like this option too! It will require a bit of writing. I also think all these should probably be in the appendix with a paragraph or two discussing them in the main text.",
            "createdAt": "2025-07-28T12:23:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3126990088",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs66YlFC",
            "author": {
              "login": "MarcoGrotteria"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Agree option 1 might be better.  Tariff actions may have less persistence than foreign aid so the nature of selection might be different.\r\n\r\nBest regards,\r\nLakshmi Naaraayanan\r\n________________________________\r\nFrom: Marco Grotteria ***@***.***>\r\nSent: Monday, July 28, 2025 1:20 pm\r\nTo: MaxMillerLab/foreign_influence ***@***.***>; MaxMillerLab/foreign_influence ***@***.***>\r\nCc: Mention ***@***.***>; Miller, Max ***@***.***>; Lakshmi Naaraayanan ***@***.***>\r\nSubject: Re: [MaxMillerLab/foreign_influence] Motivating evidence tariffs (Issue #125)\r\n\r\nI would say option n.1 . There is no reason why selection has to be the same and I guess tariff are rarer and even affect multiple countries at the same time. So maybe it\u2019s not crazy\r\n\r\nFrom: Max Miller ***@***.***>\r\nDate: Monday, 28 July 2025 at 14:18\r\nTo: MaxMillerLab/foreign_influence ***@***.***>\r\nCc: Marco Grotteria ***@***.***>, Mention ***@***.***>\r\nSubject: Re: [MaxMillerLab/foreign_influence] Motivating evidence tariffs (Issue #125)\r\n\r\n[https://avatars.githubusercontent.com/u/37848132?s=20&v=4]MaxMillerLab left a comment (MaxMillerLab/foreign_influence#125)<https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3126969498>\r\n\r\n@MarcoGrotteria<https://github.com/MarcoGrotteria> checked this out today.\r\n\r\nResults:\r\n\r\n  1.  Similar cross-sectional regression do NOT \"work\" for tariffs. What I mean is that in the cross-section countries that meet do not have significantly higher numbers of aligned actions;\r\n  2.  Unidentified local projections work very well for cumulative aligned actions;\r\n  3.  Unidentified local projections do NOT work very well for trade-weighted tariff rate.\r\n\r\nWhat do do?\r\nI think we have a couple of options:\r\n\r\n  1.  Report both and talk about how selection might be different (e.g. larger countries tend to lobby more and get more foreign aid, but there are not necessarily more tariff bills about those countries);\r\n  2.  Report only the tariff unidentified results;\r\n  3.  Report only identified results.\r\n\r\nWe can chat about best course of action tomorrow.\r\n\r\n\u2014\r\nReply to this email directly, view it on GitHub<https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3126969498>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFMOUSWB5FPBU2IKJJI26533KYIJDAVCNFSM6AAAAACBPWM3IWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTCMRWHE3DSNBZHA>.\r\nYou are receiving this because you were mentioned.\r\n",
            "createdAt": "2025-07-28T12:28:13Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3127005506",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLsBrFs66YmKy",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MarcoGrotteria and @lnaaraayanan sounds good! I'll put together the tables!",
            "createdAt": "2025-07-28T12:29:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125#issuecomment-3127009970",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-14T17:45:38Z",
        "labels": [],
        "milestone": null,
        "number": 125,
        "projectItems": [
          {
            "status": {
              "optionId": "08afe404",
              "name": "Ready"
            },
            "title": "Foreign Influence"
          }
        ],
        "title": "Motivating evidence tariffs",
        "updatedAt": "2025-07-28T12:29:24Z",
        "url": "https://github.com/MaxMillerLab/foreign_influence/issues/125"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjM3ODQ4MTMy",
            "login": "MaxMillerLab",
            "name": "Max Miller"
          }
        ],
        "body": "**Goal:** perform similar analysis on contracts that we did for subsidies.\n\n**Ingredients:**\n- NETS parent data\n- NETS merged with government contracts\n- Meetings data\n\n**Analyses:** \n1. Look at contract amount unidentified;\n2. Use committee switchers;\n3. Use redistricting;\n4. Use congressional exits;\n5. Examine employment;\n6. Examine inefficiency measures from Spenkuch and Teso paper;\n\n**Population:**\n- Foreign firms\n- Lobbying domestic firms for domestic firms hiring FARA lobbyists",
        "comments": [
          {
            "id": "IC_kwDOLsBrFs6tHhLj",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "This is on pause until #99 is complete",
            "createdAt": "2025-05-23T13:28:59Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-2904429283",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs6xNqnf",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "This is on pause until #99 is complete",
            "createdAt": "2025-06-14T20:27:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-2973149663",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs6yG0X9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "This is on pause until https://github.com/MaxMillerLab/foreign_influence/issues/99 is complete",
            "createdAt": "2025-06-19T13:37:15Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-2988131837",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs62KFVC",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Moving this off pause with completion of #99 ",
            "createdAt": "2025-07-10T07:40:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-3056096578",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs63hEyY",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "No progress this week aside from presentation. We will have overruns and delays with #122 finishing. This should give me all that I need!",
            "createdAt": "2025-07-16T14:37:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-3078900888",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLsBrFs66OVFz",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MaxMillerLab - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98#issuecomment-3124318579",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-05-20T17:44:51Z",
        "labels": [],
        "milestone": null,
        "number": 98,
        "projectItems": [
          {
            "status": {
              "optionId": "08afe404",
              "name": "Ready"
            },
            "title": "Foreign Influence"
          }
        ],
        "title": "Add contracts analysis",
        "updatedAt": "2025-07-27T11:18:35Z",
        "url": "https://github.com/MaxMillerLab/foreign_influence/issues/98"
      }
    ],
    "MaxMillerLab/democracy": [
      {
        "assignees": [
          {
            "id": "U_kgDOBtDYiQ",
            "login": "spkim1228",
            "name": ""
          }
        ],
        "body": "Figure out minimum datawork that needs to be done to produce main text results, separate from the appendix.\n\nThis involves understanding all the necessary variables to get the final results, grouping by various variables, including equity, macro, political, event, etc.\n\nThe output will involve a master dataset with all the necessary variables and data to replicate currently existing results.",
        "comments": [
          {
            "id": "IC_kwDOMc0jnM667Jas",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 This is mostly going to be parsing through the steps in the newDemocratization2.do script. The other scripts that do the data cleaning are reasonably well organized.",
            "createdAt": "2025-07-30T12:23:43Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/12#issuecomment-3136067244",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM67VJr8",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'm currently almost done with identifying which datasets are needed and not needed to create any of the tables and figures in the main text of the code (Tables 1-12 and Figures 1-8). I am planning on assembling this dataset into a new master dataset. The current one created from the `newDemocratization2.do` in `source/derived/results` is called `allData_new.dta` located in `datastore/Data/CleanedData`. I will most likely name is something similar in the same folder.",
            "createdAt": "2025-08-01T06:43:02Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/12#issuecomment-3142884092",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMc0jnM67bTlM",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 sounds great!",
            "createdAt": "2025-08-01T12:56:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/12#issuecomment-3144497484",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-29T18:28:02Z",
        "labels": [],
        "milestone": null,
        "number": 12,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Who values democracy?"
          }
        ],
        "title": "Figure out Minimum Datawork to Obtain Main Results",
        "updatedAt": "2025-08-01T12:56:52Z",
        "url": "https://github.com/MaxMillerLab/democracy/issues/12"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOBtDYiQ",
            "login": "spkim1228",
            "name": ""
          }
        ],
        "body": "The JPE instructions request that all datasets include a README.pdf containing a list of all files included and guiding the user on how to use them for replication. Additionally, this denotes a difference in procedure for proprietary datasets. I must make note of which datasets are proprietary and summarize the information accordingly.",
        "comments": [
          {
            "id": "IC_kwDOMc0jnM65lubC",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 yes, please let me know! We should definitely make the readmes... This is where AI will very much be our friend.",
            "createdAt": "2025-07-24T14:22:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3113674434",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM66OaEB",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Not assigned to a project\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:53:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3124338945",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM66nOwn",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Have not started this yet, will begin later today.",
            "createdAt": "2025-07-29T06:16:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3130846247",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMc0jnM66pOe9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 sounds good! Please provide regular updates on this. Getting the replication code done is a very high priority issue for me.",
            "createdAt": "2025-07-29T08:54:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3131369405",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM67UoIJ",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Correct me if I'm wrong but I'm not entirely sure if any of the datasets qualify as proprietary as we are not using any `orig` files and the files for analysis have been modified in some way (does this still qualify them as proprietary?). If so, the proprietary datasets include anything with GFD, IBES Global, or FactSet. This would necessitate getting an data exemption for these datasets from the editor.",
            "createdAt": "2025-08-01T06:25:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3142746633",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMc0jnM67bTHj",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 I will get some clarification on this, but I think we are allowed to share GFD, IBES Global, and FactSet data provided they do not post it. I will email the people about this. For now, I would put together the README.md's for all data files.",
            "createdAt": "2025-08-01T12:56:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/11#issuecomment-3144495587",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-24T05:25:58Z",
        "labels": [],
        "milestone": null,
        "number": 11,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Who values democracy?"
          }
        ],
        "title": "Creating README files for all Datasets",
        "updatedAt": "2025-08-01T12:56:11Z",
        "url": "https://github.com/MaxMillerLab/democracy/issues/11"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOBtDYiQ",
            "login": "spkim1228",
            "name": ""
          }
        ],
        "body": "Checking figures and code that creates figures to see if it matches the JPE instructions for Figures. I am planning on cross checking it with the files in `source/figures`. These guidelines include:\n\n- [x] Making the figures Black & White (if you were planning on doing color printing, please correct me!)\n- [x] High resolution PDFs\n- [ ] It also requests that figure legends be separate from the figure itself.\n\nThe other requirements appear to be taken care of in terms of labelling.",
        "comments": [
          {
            "id": "IC_kwDOMc0jnM65lr6R",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 let me share the email I got from the journal. I think I will pay for color. And if you could update the figures and tables to meet their style it would be fantastic!",
            "createdAt": "2025-07-24T14:19:52Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/10#issuecomment-3113664145",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM65ltTk",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 I added you to the project for this. Please add a start date and target completion date.",
            "createdAt": "2025-07-24T14:21:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/democracy/issues/10#issuecomment-3113669860",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM67UGQA",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "All the tables look good! I need to work on having separate legends for the figures but more pressingly, the JPE instructions states \"Tables should be included in the text file, following the references\" and \"Figures and online-only materials (if applicable) should be uploaded as separate files\". Is the final version of the manuscript `Miller_Submission.pdf` in `source/paper`? And if so, would you like me to proceed with creating a manuscript version in this format?",
            "createdAt": "2025-08-01T06:09:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/10#issuecomment-3142607872",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOMc0jnM67bSCL",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228, yes that should be the final version. Could you please create a folder called `publication` in `source/paper` and make the necessary changes there?",
            "createdAt": "2025-08-01T12:54:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/10#issuecomment-3144491147",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-24T05:22:18Z",
        "labels": [],
        "milestone": null,
        "number": 10,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Who values democracy?"
          }
        ],
        "title": "Checking Figures for JPE Format",
        "updatedAt": "2025-08-01T12:54:36Z",
        "url": "https://github.com/MaxMillerLab/democracy/issues/10"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjM3ODQ4MTMy",
            "login": "MaxMillerLab",
            "name": "Max Miller"
          },
          {
            "id": "U_kgDOBtDYiQ",
            "login": "spkim1228",
            "name": ""
          }
        ],
        "body": "The paper needs to be reformatted to allow it to be in JPE style. Notes on how to do this can be found [here](https://uchicago.app.box.com/s/r30zd1bllp361x8untzruwbfov0ptr4z).",
        "comments": [
          {
            "id": "IC_kwDOMc0jnM6rNg8v",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Will likely assign this to @spkim1228 when things calm down on foreign_influence",
            "createdAt": "2025-05-12T12:52:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/7#issuecomment-2872446767",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM6z5VjM",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Behind on this... need to get it done",
            "createdAt": "2025-06-30T07:51:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/7#issuecomment-3018152140",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM62J9a9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Behind on this... need to get it done",
            "createdAt": "2025-07-10T07:32:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/7#issuecomment-3056064189",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM63hE8D",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Behind on this... need to get it done",
            "createdAt": "2025-07-16T14:38:04Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/7#issuecomment-3078901507",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOMc0jnM66OaD6",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MaxMillerLab @spkim1228 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:53:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/democracy/issues/7#issuecomment-3124338938",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-05-02T13:54:58Z",
        "labels": [],
        "milestone": null,
        "number": 7,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Who values democracy?"
          }
        ],
        "title": "Format the paper for publication in JPE",
        "updatedAt": "2025-07-27T11:53:34Z",
        "url": "https://github.com/MaxMillerLab/democracy/issues/7"
      }
    ],
    "MaxMillerLab/colonialism": [
      {
        "assignees": [
          {
            "id": "U_kgDODJxyJQ",
            "login": "Ukhansky",
            "name": ""
          }
        ],
        "body": "I\u2019ve been reviewing the OCR pipeline and noticed a few things we should improve before scaling it further. While the current script works for extracting Markdown, it\u2019s not saving all of the data returned by the API: images referenced in the Markdown and the full API response object itself.\n\nAlso, there are cases where pages appear to be silently skipped (but we don't know). We need clearer logging when that happens and a retry mechanism to make sure we don\u2019t miss data.\n\n## Steps\n\n- [x] Save the `image_base64` content from each page to a `.jpeg` file.\n- [x] Match the Markdown image references to actual saved image files (e.g., `img-18.jpeg`).\n- [x] Save the **entire OCR API response** (as `.md`) per document, for transparency and debugging.\n- [ ] Add a retry loop (with backoff) for pages that fail.\n- [x] Zip together all output from a single run (`.md`, `.jpeg`, `.json`, etc.) to make the results portable.\n\n\nRight now we\u2019re not seeing the full picture of what the API returns. Moving forward, we should be clearer on what\u2019s happening before spending on full runs (we should avoid stupid mistakes that would cost several hundred bucks). Having the raw response + page-level logging will help us identify errors earlier and make reruns more precise if needed.\n\nI\u2019ll start by making some of these changes (starting with saving `image_base64` and logging skipped pages). I\u2019ll also grab a sample full API response and include it here for reference. Open to thoughts from others once the branch is up.\n",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM656Hwg",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky this looks great! Also, remember to create a branch for this and store the relevant scripts on that branch.",
            "createdAt": "2025-07-25T16:06:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3119021088",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66OVIw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "\ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Not assigned to anyone\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3124318768",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66T6nU",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": " I\u2019m fully on board with rerunning OCR across the full set of files \u2014 I\u2019m starting with a smaller batch just to avoid racking up unnecessary costs. So far, the formatting looks really clean and consistent; the PDF structure is being recognized surprisingly well.\n\nAbout the image output \u2014 I tried running the OCR with include_image_base64=True using Mistral\u2019s ocr.process() API. I also wrote code to save each image_base64 as .jpeg files. But after trying on a sample (like the 1918 Bermuda Blue Book), I saw that the images/ folder was empty \u2014 no image data was returned at all.  (I will store all the relevant code in the new branch)\n\nI checked a few more Blue Books, and it looks like there is not much visual content inside \u2014 almost no decoration, just covers or blank pages. I will check more later, but for now I think it\u2019s okay to ignore the image part and just continue working with the markdown text for NER.\n\nI think the main issue at this stage is NER. I ran a test and included a sample below. The output is still pretty messy and not super useful yet. \n\n[ner_bermuda-blue-book-1918.csv](https://github.com/user-attachments/files/21462730/ner_bermuda-blue-book-1918.csv)",
            "createdAt": "2025-07-28T06:51:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3125782996",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM66Vy4o",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky agreed this is messy! My guess is that we will need to do some preprocessing before running the NER. I think the workflow should be as follows:\n1. Save the full API output;\n2. Use a long context window LLM to characterize what is in the various markdown tables that we have;\n3. Put together tables that cover the same things into CSV files.\n\nAfter that, we can look at the tables that we have and decide what we want to do with them. In terms of long context LLMs there are a few options and we should discuss on our call.\n\nHow is the progress on step 1?",
            "createdAt": "2025-07-28T09:07:26Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3126275624",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66x6dG",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@Ukhansky](https://github.com/Ukhansky) agreed this is messy! My guess is that we will need to do some preprocessing before running the NER. I think the workflow should be as follows:\n> \n> 1. Save the full API output;\n> 2. Use a long context window LLM to characterize what is in the various markdown tables that we have;\n> 3. Put together tables that cover the same things into CSV files.\n> \n> After that, we can look at the tables that we have and decide what we want to do with them. In terms of long context LLMs there are a few options and we should discuss on our call.\n> \n> How is the progress on step 1?\n\n",
            "createdAt": "2025-07-29T18:44:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3133646662",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM66x_Gi",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thank you for proposing this! I will follow this workflow. As for step one, I still can only save the cover pic of the book. I will scrutinize an entire bluebook to see if there\u2019s anything else useful.",
            "createdAt": "2025-07-29T18:51:15Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3133665698",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM66yCPO",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky What branch is the code on? I'd like to be able to examine it.",
            "createdAt": "2025-07-29T18:56:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3133678542",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66yYdj",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "It is in /issue_32_Save-Full-OCR-API-Output-(Including-Images)-and-Improve-Script-Structure/source/derived)\n/ocr/. The two most recent update.",
            "createdAt": "2025-07-29T19:26:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3133769571",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM667Mgv",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky Thanks! Also, check out the lab manual naming conventions for branches. Everything should be lowercase and the short description should be shorter. Thanks for doing this!!",
            "createdAt": "2025-07-30T12:26:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3136079919",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM67AELn",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky can we separate out the pipeline to run things using Mistral OCR into it's own folder? I'm thinking it could be called `source/derived/ocr/mistral`. Ideally, we would have all our ocr methods in separate folders like this with common utilities across folders in `source/utils/ocr`. Does this make sense?",
            "createdAt": "2025-07-30T18:08:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3137356519",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM67FUe7",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I have moved the Mistral OCR pipeline into its own folder as you suggested (source/derived/ocr/mistral).\nAlso, I changed the branch name to follow the naming rule.\nPlease let me know if anything need to be improved.",
            "createdAt": "2025-07-31T06:38:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3138734011",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM67KrL9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky thank you!",
            "createdAt": "2025-07-31T14:11:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3140137725",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM67NrBJ",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "> [@Ukhansky](https://github.com/Ukhansky) agreed this is messy! My guess is that we will need to do some preprocessing before running the NER. I think the workflow should be as follows:\n> \n> 1. Save the full API output;\n> 2. Use a long context window LLM to characterize what is in the various markdown tables that we have;\n> 3. Put together tables that cover the same things into CSV files.\n> \n> After that, we can look at the tables that we have and decide what we want to do with them. In terms of long context LLMs there are a few options and we should discuss on our call.\n> \n> How is the progress on step 1?\n\nI looked into other long-context LLMs. Some good options include Claude 3.5 Sonnet / Opus, GPT-4-128k (OpenAI), Gemini 1.5 Pro (Google), Mistral/Mixtral with RAG (open-source, I can also try), and Command R+ (Cohere).\n\nI can try using Gemini 1.5 Pro first \u2014 it\u2019s currently free through Google AI Studio, so it\u2019s a good option to test the pipeline.\n\nFor the other models, here are some rough cost estimates for processing one Blue Book (about 50,000 tokens total):\n\nClaude 3.5 Sonnet: ~$0.30\nGPT-4-128k: ~$0.80\nGemini 1.5 Pro: Free (if under usage limit)\nLet me know if these prices seem okay \u2014 or we can try with one or two books first and see how it goes?",
            "createdAt": "2025-07-31T18:17:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3140923465",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM67Nxma",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky my guess is that we will want to try either GPT4.1 mini or Gemini Flash. MiniMax is also an option. But, first things first, let's get the output of the API right.",
            "createdAt": "2025-07-31T18:28:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3140950426",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM67QzZ9",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve now implemented the pipeline and tested it on one Blue Book.\n\nFor a single run, the output is saved as a .zip file that contains:\n\nthe full OCR result as a markdown file (one page per section),\nand all the associated images extracted from the document.\nIt looks good to me so far.\nI also uploaded the code I used and the full output as a zip file, in case you'd like to take a look.\n\nThe code is being uploaded in source/derived/ocr/mistral in branch : issue_32_save_full_ocr_api_output.\n\nLet me know if anything should be changed or improved.\n\n[bermuda-blue-book-1918_ocr_output.zip](https://github.com/user-attachments/files/21539632/bermuda-blue-book-1918_ocr_output.zip)",
            "createdAt": "2025-08-01T00:35:25Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3141744253",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM67bMs_",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky this is fantastic! Thank you! Does the API return some other structured format like a JSON? It would be helpful to understand what the actual raw output of the API is. Aside from that, this is fantastic work!!\n\nAs a last thing, remember to link the issue branch to the issue (you will see that I have done this for this issue).",
            "createdAt": "2025-08-01T12:47:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/33#issuecomment-3144469311",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-25T13:44:13Z",
        "labels": [],
        "milestone": null,
        "number": 33,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "Save Full OCR API Output (Including Images) and Improve Script Structure",
        "updatedAt": "2025-08-01T12:47:30Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/33"
      },
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjM3ODQ4MTMy",
            "login": "MaxMillerLab",
            "name": "Max Miller"
          },
          {
            "id": "U_kgDOCKUj1g",
            "login": "adityadhar0",
            "name": ""
          }
        ],
        "body": "@adityadhar0 convo with Matteo last night was helpful for me thinking through some other AP results that would help us. I think we should do the following:\n1. Construct a long-short \"labor risk factor\" by: \n   * Estimating betas on our labor strikes series, \n   * Creating portfolios (either quintiles or terciles depending on how volatile the estimates are)\n   * Subtracting bottom from top quantile and using this as a risk factor\n2. We should then do the normal Fama-Macbeth stuff to back out the price of risk and use this to calibrate the model\n3. We should estimate CAPM-betas with and without the labor risk factor and see what they look like\n4. We should see what the alpha is on colonial assets under the \"correct\" (i.e. all relevant risk factors included) model\n5. We should understand why the history literature thinks that the return to these assets were low",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM62KARk",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "I wasn't able to make any progress on this \ud83d\udc4e",
            "createdAt": "2025-07-10T07:34:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/30#issuecomment-3056075876",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM62RiNL",
            "author": {
              "login": "adityadhar0"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'll take a whack at it over the next two weeks.",
            "createdAt": "2025-07-10T15:59:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/30#issuecomment-3058049867",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM63g241",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 I again made no progress.",
            "createdAt": "2025-07-16T14:24:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/30#issuecomment-3078843957",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66OVIo",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@MaxMillerLab @adityadhar0 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:54Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/30#issuecomment-3124318760",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-07-02T08:10:45Z",
        "labels": [],
        "milestone": null,
        "number": 30,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "Revisiting asset pricing implications",
        "updatedAt": "2025-07-27T11:18:54Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/30"
      },
      {
        "assignees": [
          {
            "id": "U_kgDODJxyJQ",
            "login": "Ukhansky",
            "name": ""
          }
        ],
        "body": "@Ukhansky I would like you to run some \"off-the-shelf\" NER models on the text data that you have scraped. Here is the proposed workflow:\n1. Look for top NER models on HuggingFace\n2. Write script that uses your chosen model to locate entities.\n3. Verify success on small subsample of data\n4. Run script on the grid using GPU (that will speed things up substantially).\n5. Goal: dataset with entity-colony-year\n\nNote: we may want to use an LLM to refine our output... we can discuss this after building the NER code.",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM6yciw0",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thank you for the detailed workflow! I plan to start by reviewing top-performing NER models on HuggingFace to identify one that balances accuracy and efficiency. Once a suitable model is selected, I\u2019ll validate its performance on a small subset of the scraped text. If the initial results look good, I\u2019ll scale up processing on the full dataset using GPU resources to improve speed. The ultimate goal is to generate a structured dataset capturing entity\u2013colony\u2013year relationships.",
            "createdAt": "2025-06-22T00:01:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2993826868",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6ysbs2",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky sounds amazing! Not sure if you have access to Claude Code... but if you do, I can show you how to set things up such that it can write some amazing code for you...",
            "createdAt": "2025-06-23T21:24:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2997992246",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6ysd_9",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I tried running the script myself using the more comprehensive Cyprus Blue Books as a test case and your proposed workflow, but the results weren\u2019t particularly promising. I\u2019m now looking into whether the Colonial Office List might yield better results. I\u2019ve never used Claude Code before, so I\u2019m currently exploring how to work with it.",
            "createdAt": "2025-06-23T21:29:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2998001661",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6yse6z",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky got it! What was wrong with the results using NER?",
            "createdAt": "2025-06-23T21:30:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2998005427",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6ysgzb",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I feel that very little person-specific information has been extracted so far. I don\u2019t think it\u2019s an issue with the NER model itself, but rather that the Blue Books might not be the best source. I believe the Colonial Office List could be more useful, since it includes more detailed records of officials and their positions across different sectors.\n\nAlso, since many colonial stocks were traded on the London Stock Exchange, I\u2019m thinking of running the NER model on the 1875 Yearbook of the London Stock Exchange that I have, to see what kind of information I can extract from it.",
            "createdAt": "2025-06-23T21:34:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2998013147",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6ysk92",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky that sounds like a plan! Yes, we're going to want to run it on many things, so good to have some flexible code that can be run on all our text data.\n\nAnd makes sense on why you're not finding stuff. It would be nice to understand what info we can find in the blue books!",
            "createdAt": "2025-06-23T21:43:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2998030198",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6ytdym",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "<img width=\"849\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fc95161e-53c1-4239-96ec-b0b42eff866c\" /> It seems I've found a relatively successful model. The results I got using the Cyprus Blue Book are shown in the image. Is this the output you were looking for?",
            "createdAt": "2025-06-23T23:23:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-2998262950",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6y4_ns",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky this is looking great! Yes, this is what I am looking for!",
            "createdAt": "2025-06-24T17:22:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3001285100",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6y5BQV",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "That's great! Next, I'll do the same thing for all the Blue Books and Colonial Office Lists. By the way, I wish you a wonderful experience in Italy!",
            "createdAt": "2025-06-24T17:25:06Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3001291797",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6y524X",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky thanks!",
            "createdAt": "2025-06-24T18:40:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3001511447",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6zhK32",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve already compiled the entity\u2013colony\u2013year mappings from all available Blue Books and Colonial Office Lists, but I\u2019m still missing data for the Indian region. As a substitute, I\u2019ve identified the India Office List as a relevant source.\n\nThe challenge is that the text-recognized versions on Internet Archive only cover years after 1900. I\u2019ve found pre-1900 versions from other sources, but these are still in scanned image format without OCR.\n\nSo, I\u2019m currently considering trying some off-the-shelf OCR models available on Hugging Face to convert these scans into text. Once that\u2019s done, I\u2019ll run an entity recognition model to extract the relevant entities.\n\n",
            "createdAt": "2025-06-27T06:18:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3011816950",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6zhjtP",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky we have some OCR and parsing scripts we could try, if you want. \n\nAnother option is [here](https://huggingface.co/nanonets/Nanonets-OCR-s) which is new and supposed to be very powerful. @radvilaspelanis is running our OCR script on the grid and RCP right now and might be able to provide some pointers!",
            "createdAt": "2025-06-27T06:56:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3011918671",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM60E8D5",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "While working on India Office Lists outside the 1910\u20131936 range, I tried using the nanonets/Nanonets-OCR-s model you recommended. However, I keep running into the FlashAttention2 issue \u2014 specifically, it requires CUDA or ROCm, which isn\u2019t supported on macOS systems that rely on Metal and CPU/Neural Engine architectures. I'm currently using a Mac.\n\nI may try running the workflow on the HBS grid instead. However, it seems like the environment isn't set up properly at the moment, so lots of code isn't running. I'm currently troubleshooting it.",
            "createdAt": "2025-06-30T23:51:26Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3021193465",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM60MKZ0",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "Oh yes! The one downside of Mac is no CUDA support. You an do it on either the Grid or RCP, it is your choice. I'm also happy to pay for other cloud services.\n\nLet me know if I can help! Also @radvilaspelanis has experience with this and can help you too.",
            "createdAt": "2025-07-01T09:52:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3023087220",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM60ausU",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Regarding the names extracted from the Blue Book, there are cases where we cannot determine the individuals\u2019 exact occupations. To address this, I\u2019ve included some sample .txt files and original PDF images so that you can assess whether the converted text format is sufficient for identifying a person's role.\n\n1.\n\n<img width=\"606\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a18dd071-a056-45d5-ada3-10368710636a\" />\n<img width=\"606\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e831e5df-c0df-4d21-a883-cac6ca4b11b9\" />\n<img width=\"606\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4b9764f5-52ef-480f-b3e1-c757b3bebc7d\" />\n\n2.\n\n<img width=\"507\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2756619e-6816-4055-82d7-a607d9beef40\" />\n<img width=\"507\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cb05f9c9-161c-4369-8933-88440bf9fe20\" />\n<img width=\"731\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/86a69134-ab51-4bcf-a9cd-6be63806486e\" />\n\n3.\n\n<img width=\"687\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/aa777065-4f24-4c29-bd87-7831822b0e2a\" />\n<img width=\"687\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/782fbd67-6ce8-4f00-96f8-9aae537fdd50\" />\n<img width=\"687\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fa491b2a-6a06-4bdf-a082-b336292a4662\" />\n\nAs you can see, not all extracted names are the ones we\u2019re interested in. For example, names of ordinary school teachers or individuals mentioned in death records are also included. However, I believe the .txt files still preserve the table structures fairly well.\n\nNow I'm considering whether to optimize the name extraction script to also capture surrounding information to help infer each person\u2019s role, adding a new column called detail. But running this enhanced script would be computationally expensive.\n\nAlternatively, after reviewing the overall structure of the Colonial Blue Book, I noticed that we might only need to extract names from specific sections\u2014such as CIVIL ESTABLISHMENT and COUNCILS AND ASSEMBLIES\u2014as these likely contain individuals more central to colonial administration. The table of contents of the Blue Book is shown below:\n\n\n\n<img width=\"484\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5af47936-75e6-46c4-b277-fc34615f9232\" />\n\nI\u2019m unsure whether limiting our extraction to these categories is the right approach, but it seems promising. I\u2019m also reviewing the structures of Blue Books from other colonies to see if a similar method can be applied consistently.",
            "createdAt": "2025-07-02T08:15:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3026905876",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM60a8Bo",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "[BlueBookBritishGuiana1913.txt](https://github.com/user-attachments/files/21014394/BlueBookBritishGuiana1913.txt)\n\n[BlueBookBritishGuiana1913_djvu_entities.csv](https://github.com/user-attachments/files/21014403/BlueBookBritishGuiana1913_djvu_entities.csv)\n\nI've also included the sample .txt file from the Blue Book along with the list of extracted names here, so you can play around with them if helpful. The original PDF is too large to upload directly, so I\u2019ve uploaded it separately to Dropbox. You can access it via this link:\nhttps://www.dropbox.com/scl/fi/laraovysd1cp8hvlk909f/blue-book-british-guiana-1913.pdf?rlkey=kn98huntgbt44la2d2cklgo5n&st=luv58l9j&dl=0",
            "createdAt": "2025-07-02T08:34:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3026960488",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM60bzQO",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky this is quite useful! Ok, I think we will need to actually reparse the PDFs unfortunately... I think the nanonets package is supposed to be quite good at locating tables like these. Two others we could try too:\n\n[Mistral OCR](https://docs.mistral.ai/capabilities/OCR/document_ai_overview/): this is supposed to be excellent\n[Layout Parser](https://layout-parser.github.io/): made for historical data\n\nI have code to run Mistral OCR already, so we could try it. The downside is that it will likely be pretty expensive, so we might want to see if the other options can do what we need. To be clear, we need an OCR that can process tables. In fact, I think this is all that we need for now.",
            "createdAt": "2025-07-02T09:43:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3027186702",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM60mZJ2",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'm currently exploring how to use LayoutParser, but I'm not entirely sure if it will work for my needs. I'm looking for a way to integrate LayoutParser into a PDF re-parsing workflow that will allow me to generate a more usable .txt version of the documents.\n\nTo proceed with this, I may need to purchase a Google Cloud Vision API credential.\n",
            "createdAt": "2025-07-03T01:03:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3029963382",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM60pemR",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky Sounds good! In two weeks, I'll have access to AWS textract through HBS, so we can try that too!",
            "createdAt": "2025-07-03T05:12:13Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HOORAY",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3030772113",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM602wXW",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "When using Layout Parser to detect tables, the coordinates of different columns often have to be found manually using image inspection tools like GIMP. But with thousands of charts or documents, it's obviously not practical to manually locate these coordinates for each one. That\u2019s why I feel Layout Parser might not be an ideal choice for this task. On the other hand, if we just extract all the text from the full page, it kind of defeats the purpose.\n\n<img width=\"1304\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/be4ad800-e1bb-4f17-a046-22590912da13\" />\n\nI'm looking for alternatives.",
            "createdAt": "2025-07-04T02:46:47Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3034252758",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61GkLf",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky got it! Looks like Mistral or nanonets are our best bet! Surya also has some functionality for this!",
            "createdAt": "2025-07-05T07:48:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3038397151",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM61Gp3u",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ll focus on exploring Mistral and Nanonets.\nBy the way, would it be possible for me to take a look at the previous OCR code? I think it would be really helpful. Could you let me know if it\u2019s available on GitHub, Dropbox, or elsewhere?\nThanks so much for your guidance \u2014 and happy July 4th!",
            "createdAt": "2025-07-05T07:58:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3038420462",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61G9xw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky It should be in the repo! @radvilaspelanis can you provide some guidance on this?",
            "createdAt": "2025-07-05T08:27:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3038502000",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM61HBSh",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I found the code that was used previously \u2014 I\u2019ll take a look and hopefully it\u2019ll be helpful. If I run into any issues, I\u2019ll reach out.",
            "createdAt": "2025-07-05T08:38:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 2
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3038516385",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61Q-ZJ",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Thanks again for your help earlier. I\u2019ve successfully set up my Conda environment on HBS Grid and am now beginning to test some OCR tasks on PDF documents.\n\nWhile reading through the lab wiki, I saw that GPU access on HBS Grid requires prior authorization. Since some of the OCR models I\u2019m using are quite compute-intensive, I believe GPU access would really help. Could you please advise on how I might request it?\n\nAlso, I noticed that the original environment file (`source/lib/surya.yaml`) includes outdated packages and uses Tsinghua mirrors, which aren\u2019t ideal for US users. I created an updated version that works better for me \u2014 happy to share it on GitHub if it could be useful to others.\n\nThanks so much again!",
            "createdAt": "2025-07-06T07:43:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3041125961",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61c-CR",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky yes, please upload the more US friendly one! Also, here is the link to the GPU request form!\n\nhttps://forms.office.com/pages/responsepage.aspx?id=Tlb9CUK_IUOPLbjkgvhjXMoIB6PHisBIlawtyGb7ibhUNTJJOERNR1pNRzUzS0g4WkZKWjNHVjBTSy4u",
            "createdAt": "2025-07-07T10:01:00Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3044270225",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63hBla",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky I think we can close this for now because we need to re-OCR things. Current plan is to use Mistral. Does this sound right to you?",
            "createdAt": "2025-07-16T14:35:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3078887770",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63iR9l",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yes. I will prepare for the markdown file right now and submit a pull request.",
            "createdAt": "2025-07-16T15:45:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3079216997",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM66OVIh",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n- Issue is 31 days overdue (target date was: 2025-06-26)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/28#issuecomment-3124318753",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-06-18T16:43:26Z",
        "labels": [],
        "milestone": null,
        "number": 28,
        "projectItems": [
          {
            "status": {
              "optionId": "61e4505c",
              "name": "Ready"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "Run NER on colonial exposure documents",
        "updatedAt": "2025-07-27T11:18:53Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/28"
      },
      {
        "assignees": [
          {
            "id": "U_kgDODJxyJQ",
            "login": "Ukhansky",
            "name": ""
          }
        ],
        "body": "@Ukhansky please scrape the three sources that you mentioned in #21. \n\n**Sources to scrape:**\n- [x] Blue Books\n- [x] Colonial Office Lists\n- [x] India \u2013 Not included in Blue Books\n\n**Instructions:**\nPlease store scripts you use in `source\\derived\\colonial_exposure` and remember to number them in the order they should be run. Please store the scraped files into three separate zipfiles in `datastore\\raw\\colonial_exposure`. The zipfiles should be titled `blue_books.zip`, `colonial_office_lists.zip`, and `india.zip`. Inside them should be the OCRed text data. If possible, please give each file inside an informative name (e.g. jamaica_1901.txt).\n\n**Other:**\nIn the project space (which I have connected), please provide a target end date for this (e.g. when you expect it to be finished).",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM6u0Qsf",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve started working on the scraping task for the following sources:\n\nBlue Books\nColonial Office Lists\nIndia (not included in Blue Books)\n\nRight now, I\u2019m focusing on extracting data from Internet Archive collections. However, I\u2019ve encountered a key issue:\nthe pages are dynamically rendered with JavaScript, which I haven\u2019t worked with before. As a result, standard scraping tools like requests and BeautifulSoup aren\u2019t sufficient \u2014 the data (titles, year filters, OCR text, etc.) isn\u2019t present in the raw HTML.\n\nSo I\u2019m currently learning how to handle JavaScript-rendered pages and testing a solution using Selenium to simulate browser behavior and extract the needed content year by year. I\u2019m also looking into whether there are any underlying APIs or JSON endpoints that can simplify the process.\n\nPlanned Workflow:\n\nStore scripts in: source/derived/colonial_exposure/ (numbered in the order they should be run)\nOutput three .zip archives in: datastore/raw/colonial_exposure/\nblue_books.zip\ncolonial_office_lists.zip\nindia.zip\nEach archive will contain plain OCR .txt files with informative names like jamaica_1901.txt\nNext Steps:\nContinue developing and testing the Selenium-based scraper, and check for possible data endpoints.\n\nTimeline:\nI expect to have a better estimate of how long this will take by Tuesday morning, before the meeting tomorrow morning.\nOnce I\u2019ve figured that out, I\u2019ll immediately provide a target end date in the project space.",
            "createdAt": "2025-06-02T23:58:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2932935455",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6u8KIB",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky two things that might be helpful:\n1. @radvilaspelanis has some experience with using Selenium to scrape websites so he might be of use here.\n2. It might also be useful to try [Firecrawl](https://www.firecrawl.dev/). I've been wanting to try them, and I would be willing to pay for this. They'll give you 500 credits to start, so it might be worth a try.",
            "createdAt": "2025-06-03T12:28:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2935005697",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6u_i67",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I just took a quick look \u2014 Firecrawl looks interesting. I will definitely give it a shot.\n\nThat said, I might\u2019ve stumbled onto a slightly sketchy workaround \u2014 on Taobao (a Chinese e-commerce site), it seems you can get around 500,000 tokens (about $100 worth) for 10 RMB, which is like $1.40 USD.\n\nMight not be strictly legit.",
            "createdAt": "2025-06-03T15:15:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2935893691",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6vCrEI",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky I'm ok with trying it, but let's try the less sketchy options first ;)",
            "createdAt": "2025-06-03T18:43:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2936713480",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6wO6Vh",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky how is this coming along? I know you have school stuff going on, so it's ok to have no progress, but remember to comment on in-progress issues at least once every 5 days!",
            "createdAt": "2025-06-09T19:05:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2956698977",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6wQGg6",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Sorry for not leaving a comment earlier. I have my last final exam this afternoon, and I\u2019ll be back to work right after that. The markdown is already prepared, and I\u2019ll upload it as soon as I finish the exam.",
            "createdAt": "2025-06-09T20:54:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2957011002",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6xNpZ3",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky please provide an update on this when you're able to.",
            "createdAt": "2025-06-14T20:22:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2973144695",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6xQMEt",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve uploaded the colonial Blue Books to Dropbox \u2014 it\u2019s a zip file containing everything I\u2019ve collected so far. I\u2019m still scraping the rest (the script is running), and I expect to have the full set within next day. https://www.dropbox.com/scl/fi/hfxj7xvkoru0qsvdgk1wg/Blue-Books.zip?rlkey=dc5mavre9cl6arfe75pipsbyz&st=jdpifvcl&dl=0",
            "createdAt": "2025-06-15T13:01:57Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2973810989",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6xRuFA",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky fantastic! Once we have these, we should create an issue for extracting data. This is going to require looking at some of the filing and then figuring out what we want. For example, I first pass might be to use NER or an LLM to extract names and such.",
            "createdAt": "2025-06-15T16:33:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2974212416",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6xke7V",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve prepared blue_books.zip, colonial_office_lists.zip, and india.zip, but I\u2019m unable to upload them to datastore/raw/colonial_exposure because I don\u2019t have permission to edit the datastore. Could you please grant me access so I can upload the files? \n\n<img width=\"499\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ed33e34f-8442-47f6-a87b-a5a0d641c2bd\" />\n\nAlso, it looks like the data for India is quite sparse before 1900 \u2014 I\u2019m currently looking for alternative sources.",
            "createdAt": "2025-06-17T06:41:12Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2979131093",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6xvNVA",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky let me know if you have trouble with what we talked about today. Please give me and update on this ASAP.",
            "createdAt": "2025-06-17T21:53:03Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2981942592",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6x0hRg",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve stored the three data files in the corresponding Dropbox paths as requested:\n\ndatastore\\raw\\colonial_exposure\\blue_books.zip\ndatastore\\raw\\colonial_exposure\\colonial_office_lists.zip\ndatastore\\raw\\colonial_exposure\\india.zip\nEach zip file contains scanned .txt files.\n\nThe corresponding scraping scripts are also saved in source\\derived\\colonial_exposure, numbered in the order they should be run. The scripts are ready to execute.\n\nI\u2019m currently still scraping the PDF files. Since many of them are quite large (some are several dozen MB), it\u2019s taking a bit longer. I\u2019m aiming to have them uploaded to Dropbox by June 21.",
            "createdAt": "2025-06-18T09:07:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2983335008",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6x6u8T",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky this sounds great! See issue #28 for follow up.",
            "createdAt": "2025-06-18T16:39:29Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-2984963859",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6z5VSj",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky any update here?",
            "createdAt": "2025-06-30T07:51:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3018151075",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM60EPa5",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I\u2019ve uploaded the colonial_office_list, the 348 Blue Books, and all the India Office Lists after 1900 that I could find in PDF format to Dropbox. They are stored under:\n\nColonialism/empirics/data/raw/\n\nThe two relevant ZIP files are:\n\nblue_books_pdf.zip\ncolonial_office_pdfs.zip\nThe India Office Lists include the information we're looking for on India. I used two different data sources for the lists before and after 1910:\n\nFor 1910\u20131936, I found the PDFs on the Internet Archive.\nFor the remaining years, I sourced them from the British Library\u2019s repository here:\nhttps://bl.iro.bl.uk/concern/datasets/cff86b87-1630-4bae-a7ec-c4506b0d1321?locale=en\nI bundled them into a single ZIP file named india_office_lists_pdf.zip, also stored in the same Dropbox folder.\n\nFor the other years, I\u2019m still running OCR, since there are no plain text versions available. I actually ran into a few issues during this process, which I\u2019ll explain in detail in Issue #28.",
            "createdAt": "2025-06-30T22:26:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3021010617",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM60MIqo",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky thanks!",
            "createdAt": "2025-07-01T09:50:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3023080104",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM62J-EF",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky is the scraping done for this, btw?",
            "createdAt": "2025-07-10T07:32:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3056066821",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM62ciYr",
            "author": {
              "login": "Ukhansky"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Yes, this section has been completed. The Blue Books from the various colonies, the Colonial Office List, and the India Office List have all been uploaded to Dropbox. May I proceed to close this issue and prepare a corresponding markdown file?",
            "createdAt": "2025-07-11T07:14:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3060934187",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM62dR6P",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky yes please! Also, please look at the wiki for how to handle checked boxes in issues (you should check the ones at the top and copy them into the closing comment).",
            "createdAt": "2025-07-11T08:03:31Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3061128847",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66OVIa",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@Ukhansky - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n- Issue is 36 days overdue (target date was: 2025-06-21)\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:52Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/24#issuecomment-3124318746",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-06-01T20:22:14Z",
        "labels": [],
        "milestone": null,
        "number": 24,
        "projectItems": [
          {
            "status": {
              "optionId": "df73e18b",
              "name": "In review"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "Scrape colonial exposure sources",
        "updatedAt": "2025-07-27T11:18:52Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/24"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOCKUj1g",
            "login": "adityadhar0",
            "name": ""
          }
        ],
        "body": "@MaxMillerLab this is to keep track of the second pass at the model. \n\nWe currently have \n1. Domestic macroeconomic environment is a standard Lucas Tree, colonial asset is the same process\n2. Ex-ante wealth is distributed Pareto\n3. In each period, voting share increases by $s_t$ with probability $p$, where Elites set the probability $p$\n4. Tax policy is implemented by the median voter $v_t/2$. \n5. Colonial asset decreases willingness to repress\n\nTo add:\n1. Asset pricing implications - want to show colonial asset acts as a hedge.\n2. Colonial asset production with declining returns to scale (most productive colonies exploited first)\n3. Potential growth-redistribution tradeoff\n4. Potentially allow $s_t$ to be negative\n",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM6uEVnk",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 awesome! Would you mind working on this in a separate branch? See the guide [here](https://github.com/MaxMillerLab/lab_manual/wiki/Working-on-issues-in-Github) on how to do this. And apologies... I swear I'm following these new procedures too... they're meant to make it so that we can add additional RAs on and off the project a bit more easily.",
            "createdAt": "2025-05-29T19:28:11Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-2920372708",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6uEe4E",
            "author": {
              "login": "adityadhar0"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Think it's done - let me know if it works.",
            "createdAt": "2025-05-29T19:46:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-2920410628",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6uLgq1",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 looks great!",
            "createdAt": "2025-05-30T12:22:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-2922252981",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6xNpn0",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 can you provide an update here when you get a chance?",
            "createdAt": "2025-06-14T20:23:47Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-2973145588",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6yHADq",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 we discussed an update on this and much of this is described in overleaf.",
            "createdAt": "2025-06-19T13:50:17Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-2988179690",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6zK8YO",
            "author": {
              "login": "adityadhar0"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Update on model as of 6.25. \n\n1.1: Macroeconomic environment: two separate Lucas trees with exogenous growth, shares in the Domestic tree are distributed Pareto, top 1/N fraction is held by the 'Elites'\n1.2: Fiscal policy: v_t denotes the enfranchised share of the population, the median voter at v_t/2 decides fiscal policy as a single linear tax paid back in equal parts to all citizens. We can alter it so the Elite do not receive any redistribution and each other fraction receives 1/(N-1)Y_d(tax - (1/2 omega)tax^2) (where there is deadweight loss in taxation). There is a closed form solution to the tax rate at every given enfranchisement level.\n1.3: Democratizations: Elites can pay a cost to repress democratization; the cost function is such that Elites can never fully block democracy. This section defines the Elites' maximization problem over the probability, and does not give a closed form solution but details comparative statics.\n1.4: Asset pricing implications: Solve for the interest rate as 1/E[M]. The derivation of the SDF is left to the appendix. Through the covariance term between the SDF and the risky assets, the argument is made that the domestic asset covaries more negatively with the SDF and consequently requires a higher risk premium - intuitively, the domestic asset pays low returns in more bad states (domestic risk, taxation risk) than the colonial asset does (only affected by colonial risk). This mechanically explains lower domestic returns in the colonies.\n1.5: Endogenous colonization. Investors have a menu of trees offered, ordered in decreasing levels of a tree's growth rate. There is a common colonial shock rather than heteroskedastic shocks. There are now two value functions: what is the p of repression Elites choose, what is the share of asset c that the Elites purchase. We define FOCs and some comparative statics that link democratization to colonization: repression occurs more when the cost of colonization is high or the productivity of the colonial asset is low; and that link colonization to democratization: purchases of colonial assets increase as the cost of repression increases - when it is cheap to repress protests, Elites will not hedge domestic risk with outside income.\n1.6: Simulations - in progress, will add in endogenous colonization.\n\nAppendix sections:\nA.1: Derivation of comparative statics for basic two-tree model.\nA.2: Re-writing the Elites' problem as a Bellman equation to show that including future utility does not materially shift the argument direction, only increases its magnitude.\nA.3: Derivation of the SDF and the risk-free asset. \nA.4: Price of the risky assets as best as possible - could use some checking. Have also done price/consumption ratios.\nA.5: Derivation of comparative statics and FOCs for endogenous colonization process.\nA.6: Description of portfolio choice when colonial assets have different variances. Nothing significant changes, only that it is possible for Elites to prefer asset i over asset j, even if \\bar y_i < \\bar y_j: because enough negative shocks have hit asset j that the consumption stream is, in expectation, greater for asset i.\n\nWe can add s_t being negative into Appendix A.2, because if it is written as a Bellman that makes it easier, otherwise it does not matter. I have described a little bit that the comparative statics in 1.5 imply an upper bound on the level of democratization. In spirit, however, I think the model is largely done for a strong second pass, and I've run through to the best of my abilities to make sure the equations all check out.\n",
            "createdAt": "2025-06-25T20:04:30Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-3005990414",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6zNHOR",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 Damn this sounds awesome!",
            "createdAt": "2025-06-25T23:52:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-3006559121",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM61I5q_",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 from slack it seems like you derived the beta with and without OVB on this!",
            "createdAt": "2025-07-05T14:28:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-3039009471",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63g_BK",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 I know you have been working on this/talking to folks. Could you give an update here?",
            "createdAt": "2025-07-16T14:32:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-3078877258",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM66OVIO",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@adityadhar0 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n- No target completion date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/23#issuecomment-3124318734",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-05-28T21:30:24Z",
        "labels": [],
        "milestone": null,
        "number": 23,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "Second pass at model",
        "updatedAt": "2025-07-27T11:18:51Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/23"
      },
      {
        "assignees": [
          {
            "id": "U_kgDOCcGcwA",
            "login": "radvilaspelanis",
            "name": ""
          }
        ],
        "body": "@radvilaspelanis this is to keep track of the OCR and parsing progress of the UK petitions data. Could you please provide regular updates of our status here?",
        "comments": [
          {
            "id": "IC_kwDOLrmnsM6pTTxW",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "sounds good! brief updates on the progress so far:\n\n1) For the first batch (batch_0), around ~70% of petitions are processed (~40,000 petitions). \n2) we also have NER results based on the first ~30,000 petitions but I realized I didn't match pages to these results so will fix that soon so we could extract some sequential pages and infer further from that point.\n3) For the other batches, I recently implemented parallel processing and we are currently extracting from 14 out of 16 batches. I noticed that the speed of OCR'ing falls proportionately to the amount of batches I am processing on a single job, even though each batch uses a separate core. I will also look into ways how to optimize that.\n4) my apologies again for today's meeting -- I should have myself figured out that you can't access my home folder and the code. thank you again for all the help on that end. I hope we can meet next week to talk through the code logic/potential avenues to optimize.\n5) After our last meeting on Thursday I also looked into Harvard's RCP - I believe under project colonialism, a launcher needs to be initialized (\"Please contact the project owner to assign a launcher.\") and then we can also use these resources to speed up the extraction.",
            "createdAt": "2025-04-29T22:51:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2840411222",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6pY6o4",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis all this sounds great! Could you please send an email to HBS Research Computing Services (RCS) to ask about assigning the launcher? Please CC me. I'm not 100% sure why you can start your own launcher. Thanks a ton and excited to speed this up!!",
            "createdAt": "2025-04-30T12:53:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2841881144",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6ptDJ1",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis launcher has been started. Are you able to access and run stuff?",
            "createdAt": "2025-05-02T13:05:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2847158901",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6py_vG",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "thank you Max! I'm able to access it and just tested some code - everything works. I'll put down all extraction codes and get it going there over today/tomorrow.",
            "createdAt": "2025-05-03T17:13:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2848717766",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6p07P2",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis fantastic! Let me know when you start running so I can monitor cost!",
            "createdAt": "2025-05-04T13:34:34Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2849223670",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6qZFKo",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis I'm reaching out to RCS now to make sure they don't forget about helping us transfer",
            "createdAt": "2025-05-07T13:54:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2858701480",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6rNmBp",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis putting some more pressure on IT...",
            "createdAt": "2025-05-12T12:59:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2872467561",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6sKzGH",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis can you give a status update on the OCR? I know we are waiting on the RCP stuff to start the parsing.",
            "createdAt": "2025-05-17T17:49:09Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2888511879",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6sNgfT",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "yes! briefly: 3 days of ONLY OCR'ing and we have ~1GB of data extracted from 12 different tar files. in regards to size, that should be close to 1 full batch (out of 16 that we have) worth of data. we also have ~900MBs of batch 0 that is both OCR'ed and parsed.",
            "createdAt": "2025-05-18T21:31:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2889222099",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6sN4ls",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis man, very slow! We probably need to look into some way to speed this up. How many cores are you requesting? And how many jobs are you running simultaneously?",
            "createdAt": "2025-05-19T00:38:46Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2889320812",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6sZ1wi",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I just reoptimized some things and will get back on the new speed tomorrow around the same time when I'll see how much has been OCR'ed (should be quite faster). I am currently running 3 jobs: 1 is doing OCR on 7 batches (7 cores requested, 1 for each batch), 2nd one is doing OCR on 8 batches (using 8 cores), and 3rd one I'm using for finishing doing both OCR and parsing on batch 0, using 1 core (let me know if it would be a better idea to redirect the 3rd job onto OCR'ing). I think 3 jobs are the limit if I recall correctly from HBS IT guide.",
            "createdAt": "2025-05-19T22:48:14Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2892454946",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6sj8ra",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis sounds good! So this configuration is processing about 1GB a day, right?",
            "createdAt": "2025-05-20T16:25:29Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2895104730",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6t2D9g",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis please resume OCR. Files have been moved over to the RCP.\n\nFor future reference, if you store files to be processed in `/export/globus/mmiller_colonialism` (in addition to the main project space), I can move them over very quickly. `/export/globus/mmiller_colonialism` is our portal to the RCP.",
            "createdAt": "2025-05-28T14:48:40Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2916630368",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6u8edL",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis can I get a status update on this?",
            "createdAt": "2025-06-03T12:49:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2935088971",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6vg07N",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "thanks for understanding Max and for the note on the folders! \n\nfor OCR: I have currently requested all 36 cores available to me to handle files as pdfs, not as tars as we did before. there is one issue: I believe that for fair usage, they are restricting how many cores one is allowed to use and while one of my jobs is running with 12 cores, two other with 24 cores are currently still pending (i checked bqueues and saw that ~2.8k jobs are pending while only ~200 are runnning at the same time). additionally, if we could use more cores, e.g. overnight, that could help speed up the process even more. \n\nfor parsing, I have all the code tested and ready to run, and while I can see/download files on RCP, I can't mount Harvard research storage (in this case colonialism-Storage-8yy) into the EC2 filesystem via s3fs since it seems like I'm lacking some authorization (I tried typing my account's password but that didn't work)\n\n<img width=\"489\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5fbb01e6-c493-40c4-b227-0da3fea13d82\" />\n\n",
            "createdAt": "2025-06-05T14:11:07Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2944618189",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6vkM40",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis Hmmmm interesting! Would you be alright with moving some OCRing over to the RCP too? We can use the resources there to speed things up. It sounds like we are very constrained on the grid",
            "createdAt": "2025-06-05T17:57:22Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2945502772",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6wFXOb",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I reached out to IT people to fix that, waiting for their response. In regards to OCR'ing, all 3 jobs got through and are running, using all 36 cores - I'd be down to use RCPs resources too, my only concern is to make sure that work doesn't overlap but I think there's ways to do that.",
            "createdAt": "2025-06-08T17:43:45Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2954195867",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6wPEvU",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis which one are having trouble mounting? We can't map stuff on the RCP. I need to be the one to move stuff back and forth. If you let me know what you need, though, I can move it!",
            "createdAt": "2025-06-09T19:18:55Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2956741588",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6wfZOZ",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Sorry if I was unclear -- I merely meant that I was struggling to use the OCRed files that you already moved from grid to RCP. And from my understanding, I have to mount Harvard research storage (in this case colonialism-Storage-8yy), which is where those files are stored on RCP. on another note, they terminated by hbs account and I seem to not be able to connect to HBS vpn with my grid account based on my college email (I emailed IT about it already). for RCP, would it be possible for you to add me to the project space on my email radvilaspelanis@college.harvard.edu? thank you so much Max!",
            "createdAt": "2025-06-11T02:13:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2961019801",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6wqBE1",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis yes! Could you please send an email to research@hbs.edu and CC me? I'll then ask to have you added. And ah yes I understand now! Don't hesitate to bug the RCS team about this!",
            "createdAt": "2025-06-11T18:35:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2963804469",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6w9HSj",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "just sent out a follow up on VPN, and an email on RCP as well",
            "createdAt": "2025-06-13T02:40:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2968810659",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6yHAVw",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis do we have another update on this? Is all well with the compute resources?",
            "createdAt": "2025-06-19T13:50:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2988180848",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6yInxw",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I have gotten access to RCP but not Grid where everything is stored - something is off with them granting access to VPN, I just bugged them again. Will keep posting updates here as they reply.",
            "createdAt": "2025-06-19T16:09:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2988604528",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6yL_tl",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis Thanks a ton!! I'm sorry this is being so difficult!",
            "createdAt": "2025-06-20T00:38:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-2989488997",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6y61SR",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis still having VPN problems right?",
            "createdAt": "2025-06-24T20:26:12Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3001767057",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6y87zh",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "finally got the correct instructions -- VPN is working well now, I think the very last thing I am lacking is permissions to access mmiller_colonialism on grid, attaching the picture below\n\n<img width=\"736\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/939e69b2-16a0-4ecc-8809-0fb996340fb2\" />\n\nis this something that you could be able to grant or should I bug research people?\n\n(my current grid \"nickname\" is rcs_rpelanis)",
            "createdAt": "2025-06-25T01:36:36Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3002318049",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6y9G9m",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis which email account needs access? I can grant it.",
            "createdAt": "2025-06-25T02:08:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3002363750",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6y9qx3",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "it's rcs_rpelanis@hbs.edu",
            "createdAt": "2025-06-25T02:35:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3002510455",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6y9wil",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis that is your guest account? You're not just using your harvard email?",
            "createdAt": "2025-06-25T02:39:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3002534053",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6zN7vD",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "yes this is the guest account that RCS gave me. I don't think I'm able to use harvard email for grid",
            "createdAt": "2025-06-26T02:00:20Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3006774211",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM6zhkqH",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis done!",
            "createdAt": "2025-06-27T06:58:21Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3011922567",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM6z8f6j",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "thanks Max! will work on restoring OCRing and post an update here",
            "createdAt": "2025-06-30T12:33:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3018981027",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61BSZB",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "quick update: OCR scripts are up and running on full capacity (36 nodes); new petitions are being successfully OCR'ed.\n\nthere is a chance there might be some hiccups as I had to reinstall everything but will be tracking the progress over the weekend religiously and fix those immediately in case I see them",
            "createdAt": "2025-07-04T18:19:09Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3037013569",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM61GnMi",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "I see them! Look at those babies go!!\n\n<img width=\"776\" height=\"97\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/37fb918f-1c78-4086-a36d-532d768c1f28\" />",
            "createdAt": "2025-07-05T07:54:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3038409506",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63g-Cb",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis how are things going on this? Also, when is your internship done?",
            "createdAt": "2025-07-16T14:31:35Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3078873243",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63hcEL",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I restarted all 3 jobs last Sunday (need to do this every week) and as of my last check OCRing was going well but will check again in the evening when I have access to my personal laptop. the internship ends on 8/15!",
            "createdAt": "2025-07-16T14:53:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3078996235",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM63hgUW",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis awesome!! I hope you are enjoying it!",
            "createdAt": "2025-07-16T14:55:32Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3079013654",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOLrmnsM63sGMn",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "thanks Max:)! really appreciate it",
            "createdAt": "2025-07-16T23:39:10Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3081790247",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM64z25d",
            "author": {
              "login": "radvilaspelanis"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "brief status update: renewed the OCRing for another week, all 36 nodes in use.",
            "createdAt": "2025-07-22T02:55:19Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3100601949",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOLrmnsM66OVIG",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@radvilaspelanis - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- No target completion date\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:18:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/colonialism/issues/17#issuecomment-3124318726",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-04-28T17:22:00Z",
        "labels": [],
        "milestone": null,
        "number": 17,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Colonial Hedge"
          }
        ],
        "title": "OCR and parse petitions data",
        "updatedAt": "2025-07-27T11:18:50Z",
        "url": "https://github.com/MaxMillerLab/colonialism/issues/17"
      }
    ],
    "MaxMillerLab/propaganda": [
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjg2NDcyNDk1",
            "login": "emilysilcock",
            "name": ""
          }
        ],
        "body": "Starting the parsing of newspaper data on ProQuest. There's a lot of bit of cleaning and parsing that take a bit of time so I've made myself a tracker below so I know where I've got to \n\nFor dates, I've gone from the earliest available in the modern ProQuest dataset (though there are earlier dates from historical ProQuest) and I've gone up until the end of 2023 for now \n\n(Minor github incompetence below \ud83e\udd26\u200d\u2640\ufe0f)\n\nNewspaper | ProQuest Coverage | HTML parsed | Cleaned | Country names search | Sentiment analysis \n-- | -- | -- | -- | -- | -- \nNY Daily News | 3/1/1995+ | \u2705 | \u2705 | \u2705 | \nUSA Today | 2/17/1997+ | \u2705 | \u2705 | \u2705 | \nWSJ | 1/2/1984+ | \u2705 | \u2705 | \u2705 |  \nNY Times | 6/1/1980-8/25/2021 | \u2705 | \u2705 | \u2705 |  \nLA Times | 1/1/1985+ | \u2705 | \u2705 | \u2705 | \nChicago Tribune | 1/1/1985+ | \u2705 | \u2705 | \u2705 | \nWashington Post | 1/1/1987+ | \u2705 | \u2705 | \u2705 | \nNY Post | No ProQuest, but I have this scraped from Factiva 1998-2023 | \u2705 | \u2705 |  | \nPhiladelphia Inquirer | 1/1/1983+ | \u2705 | \u2705 | \u2705 |  | \nDetroit Free Press | 1/1/1999+ | \u2705 | \u2705 | \u2705 |  | \nThe Boston Globe | 1/1/1997+ | \u2705 | \u2705 | \u2705 |  | \nMinnesota Star Tribune | 1/1/1986+ | \u2705 | \u2705 | \u2705 |  | \n",
        "comments": [
          {
            "id": "IC_kwDOOUGQyc6wGWrL",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock Amazing! Excited to see what we get. Should give us the ability to run the most basic regressions",
            "createdAt": "2025-06-09T02:11:58Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2954455755",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc6wIUE3",
            "author": {
              "login": "emilysilcock"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "For country names, I've used data and aliases from Geonames, with all English aliases, and then removed names where another name is a subset (to speed up search). \n\nCountries where I think this will pose a problem: \n- Congo (picks up both)\n- Chad \n- Punctuation like USA v U.S.A \n\nBut I think this should do a decent job for a first run through ",
            "createdAt": "2025-06-09T07:46:25Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2954969399",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOUGQyc6wO0n-",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock awesome!! Sounds like there aren't too many issues!",
            "createdAt": "2025-06-09T18:59:18Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2956675582",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc6xNpP5",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock I moved your second comment to the initial comment because I'm horrible. Hope this is coming along reasonably well!",
            "createdAt": "2025-06-14T20:21:59Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2973144057",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc6yGw-d",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock any progress on this? Do you think it's few enough articles to where we can drink their proverbial milkshake? Let me know if it would be productive to chat! ",
            "createdAt": "2025-06-19T13:32:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2988117917",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc6yjEk6",
            "author": {
              "login": "emilysilcock"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab  sorry I've been very European and totally ignored my emails while on holiday! \n\nMaking slow but steady progress. Their machines time out periodically and I've been a bit less good at noticing when that's happened, as I've been blissfully away from my laptop. \n\nShould be done with the country counts in ~3 days. \n\nThe bad news: for what I've run already, even after compressing, the articles that mention countries are still > 4GB of data. I can only get off 15MB a week, so that's like 8 years. Unsurprisingly, the NYT coverage is about an order of magnitude bigger than the other newspapers I've run so far. \n\nThe good news: TDM studio have just announced GPT access without taking the data off. It's still in beta, so I'm expecting it to be a little clunky (everything else on there is ...), but seems quite likely we could do most things we want without extracting the data \n\nI know we put a meeting in the calendar tomorrow, but I'm wondering if we'd be better off waiting until the country counts at least are run? ",
            "createdAt": "2025-06-23T08:49:37Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2995538234",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOUGQyc6ysX8B",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock I knew it was too good to be true! We might actually have access to all NYT articles though... I can check with the library. There are some outlets we have the complete data for.\n\nAnd totally fine with meeting next week! I'll be in Italy so we're in the same time zone. I'll set a placeholder, but whenever works!",
            "createdAt": "2025-06-23T21:18:50Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-2997976833",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc60DLZE",
            "author": {
              "login": "emilysilcock"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Country counts are at datastore/derived/newspapers/country_counts - there's a few missing because I hit this week's export limit, so will get those next Monday!",
            "createdAt": "2025-06-30T21:06:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-3020731972",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOUGQyc60MHg9",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock went through a few files and there is reasonable variation! Even small countries seem to get reasonably frequent mentions, so that is good!",
            "createdAt": "2025-07-01T09:49:49Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HOORAY",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-3023075389",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc62J-vk",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock i know you (and I) were sick this week, but did you manage to make any progress? Totally fine if you weren't!",
            "createdAt": "2025-07-10T07:33:48Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-3056069604",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOUGQyc6434H7",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@emilysilcock I know you're swamped, but wanted to check in on this. From our call, I recall you're using GPT to figure out country info in the articles right now.",
            "createdAt": "2025-07-22T08:33:24Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/propaganda/issues/5#issuecomment-3101655547",
            "viewerDidAuthor": true
          }
        ],
        "createdAt": "2025-06-08T14:29:21Z",
        "labels": [],
        "milestone": null,
        "number": 5,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In progress"
            },
            "title": "Propaganda"
          }
        ],
        "title": "Newspaper country mentions and sentiment on ProQuest",
        "updatedAt": "2025-07-22T08:33:24Z",
        "url": "https://github.com/MaxMillerLab/propaganda/issues/5"
      }
    ],
    "MaxMillerLab/interest_rate_risk": [
      {
        "assignees": [
          {
            "id": "MDQ6VXNlcjM3ODQ4MTMy",
            "login": "MaxMillerLab",
            "name": "Max Miller"
          }
        ],
        "body": "Explore how well we match the data for housing and equity along the wealth dimension, for a given age group (I guess 40-45). This is the analog of Figure 8 for these outcomes",
        "comments": [],
        "createdAt": "2025-07-25T12:52:13Z",
        "labels": [],
        "milestone": null,
        "number": 14,
        "projectItems": [
          {
            "status": {
              "optionId": "",
              "name": ""
            },
            "title": "Social Security II"
          }
        ],
        "title": "Check housing and stock wealth along income and wealth",
        "updatedAt": "2025-07-25T12:52:13Z",
        "url": "https://github.com/MaxMillerLab/interest_rate_risk/issues/14"
      }
    ],
    "MaxMillerLab/census": [
      {
        "assignees": [
          {
            "id": "U_kgDOBtDYiQ",
            "login": "spkim1228",
            "name": ""
          }
        ],
        "body": "## Census documentation\n\nThere are three main goals:\n- [ ] Create list of and high level description of various datasets we have available to us in the project\n- [ ] Create detailed description of variable available in each dataset\n- [x] Understand how well census compute resources work\n\n### Dataset description\n\nThis should go through and discuss the various datasets we have, what frequency they are available at, and broadly what information they have in them. Keep a few things in mind:\n1. Our goal is to construct a firm-county-level measure of investment and profits. You should be looking for various measures that might allow up to do this.\n2. We allow want to document trends in concentration (think Herfindahl\u2013Hirschman index style measures). Think through various series that might be interesting to document this on\n3. We want to understand how to merge the data with NETS/Orbis/Contracts data. Think through identifying information that might allow for this\n\n### Variable description\n\nHere, we want:\n- Understanding of what variables are present\n- How good is there coverage (e.g. available all years, some years, basic summary stats, etc)\n- Other information you think will be helpful\n\n### Compute resources\n\n- Begin to understand what resources we have for working with large data.\n- How fast does the code run?",
        "comments": [
          {
            "id": "IC_kwDOOlmNM86uOcMb",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 is there a reason you closed this?",
            "createdAt": "2025-05-30T17:47:39Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2923021083",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM86uOdzK",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "@MaxMillerLab Ah! I created this issue in the Done item in the project space, which I think auto-closed the issue. Thanks for catching it!",
            "createdAt": "2025-05-30T17:49:44Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2923027658",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM86vL2Hc",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Currently working way through all datasets available for this project. I have roughly a good idea of how well the compute power available to us based on the available RAM. Additionally, talking with other RDC users let me know that code on large datasets do take a while but not unreasonable (usually within a few hours at most).",
            "createdAt": "2025-06-04T08:32:53Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2939118044",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM86vOzlU",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 sounds great! I would setup some scripts that log progress and save intermediate steps in a scratch folder (and then delete them at the end of the run). This way we don't lose too much time.\n\nWhen are you scheduled to next go to the RDC?",
            "createdAt": "2025-06-04T12:41:21Z",
            "includesCreatedEdit": true,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2939894100",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM86vuvlB",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I went to the RDC today and am detailing differences between years for each dataset, where all the datasets looked at so far vary columns year-to-year. I've begun constructing a mapping of related columns into panels in the markdown folder (I think it would be useful to create short scripts for each dataset that handles and processes these differences using this mapping, which I'll put in the programs folder).",
            "createdAt": "2025-06-06T06:45:27Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2948266305",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM86wh6ug",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Continuing with going through the datasets. I also created a short script to compare the columns available in a dataset between different years (to assist with creating mapping of related columns year-to-year). Looking at the number of differing columns for certain datasets, however, I'm wondering if it's worth creating mappings for certain files. If a dataset has a file for identifying data and another for questionnaire data, would it be more efficient and worthwhile to only check columns for the identifying data? I'm curious on your thoughts on this.",
            "createdAt": "2025-06-11T08:18:04Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2961681312",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM86wqIwR",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 we should probably discuss the broad variable types you are working with. If you provide a \"broad type\" to me, I can tell you if we need it or not.",
            "createdAt": "2025-06-11T18:48:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2963835921",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM86x0F7C",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Continuing with creating documentation for the datasets provided. I'm currently identifying variables that we could merge with our external datasets (NETS, ORBIS, contracts). I'm also identifying variables that could be merged across the various census datasets -- is this something that is worth continuing? Or do you think we will be mostly merging one census dataset to an external dataset at a time? ",
            "createdAt": "2025-06-18T08:31:36Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2983222978",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM86x69cd",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 this is great! I think we will proceed one at a time, but it is good to look into what we can use to merge. Part of our project with the census is merging with NETS, so we should focus on that first.",
            "createdAt": "2025-06-18T16:50:33Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-2985023261",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM86zEBP8",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I'm currently seeing which census datasets I can broadly group together, as many of them share similar identifying variables. Additionally, I'm curious on whether you think geography could be another possible merging variable with NETS or if we would want to try using another variable (I think we would have to merge NETS to another dataset prior to this though).",
            "createdAt": "2025-06-25T10:00:26Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "HEART",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3004175356",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM860aNdy",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "Continuing with identifying variables in each dataset that would be useful for merging with outside datasets, namely NETS. I wanted to bump the question above on whether geography could be useful or if it might be tedious, as it would be difficult to get geocoded information for census location data. One possible avenue for the previously mentioned extra variable for merging is NAICS and other federal classifiers, which seems to be standard across most datasets.",
            "createdAt": "2025-07-02T07:30:51Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3026769778",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM860btcf",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 I missed this! Yes, I think geography will be useful for us and it would be useful for us to understand how their geography relates to NETS. Could you please initiate the process for bringing NETS, Orbis, and contracts data into our project too? I think you can start this as a separate issue.",
            "createdAt": "2025-07-02T09:36:08Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3027162911",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM862IBkH",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I received a Kiteworks folder and a form to fill for each dataset that we want to add to the project space that are undergo a review process. I think it would be worthwhile to discuss exactly which datasets we would want to add on.",
            "createdAt": "2025-07-10T05:05:01Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3055556871",
            "viewerDidAuthor": false
          },
          {
            "id": "IC_kwDOOlmNM862Ircb",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 sounds great! I can focus on that a bit next week. Maybe we can discuss on Tuesday?",
            "createdAt": "2025-07-10T06:07:46Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3055728411",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM863g4qU",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 I added a completion date for this. Do you think this is doable?",
            "createdAt": "2025-07-16T14:26:05Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3078851220",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM866OaEy",
            "author": {
              "login": "MaxMillerLab"
            },
            "authorAssociation": "OWNER",
            "body": "@spkim1228 - \ud83d\udea8 **GitHub Police Report Violation Notice** \ud83d\udea8\n\nThis issue has been flagged for the following violations:\n\n- Issue has been inactive for 10 days (last updated: 2025-07-16)\n- No priority set\n\n---\n\n**Action Required:** Please address these violations by:\n1. Updating the issue with the missing information\n2. Providing a status update if the issue has been inactive\n3. Adjusting target dates if the issue is overdue\n\n_This is an automated message generated by the GitHub Police Report._\n",
            "createdAt": "2025-07-27T11:53:41Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3124338994",
            "viewerDidAuthor": true
          },
          {
            "id": "IC_kwDOOlmNM866nG6H",
            "author": {
              "login": "spkim1228"
            },
            "authorAssociation": "COLLABORATOR",
            "body": "I am moving the completion date to the following Tuesday.",
            "createdAt": "2025-07-29T06:01:42Z",
            "includesCreatedEdit": false,
            "isMinimized": false,
            "minimizedReason": "",
            "reactionGroups": [
              {
                "content": "THUMBS_UP",
                "users": {
                  "totalCount": 1
                }
              }
            ],
            "url": "https://github.com/MaxMillerLab/census/issues/2#issuecomment-3130814087",
            "viewerDidAuthor": false
          }
        ],
        "createdAt": "2025-05-30T17:31:58Z",
        "labels": [],
        "milestone": null,
        "number": 2,
        "projectItems": [
          {
            "status": {
              "optionId": "47fc9ee4",
              "name": "In Progress"
            },
            "title": "Census"
          }
        ],
        "title": "Create documentation for census data",
        "updatedAt": "2025-07-29T06:01:42Z",
        "url": "https://github.com/MaxMillerLab/census/issues/2"
      }
    ]
  }
}